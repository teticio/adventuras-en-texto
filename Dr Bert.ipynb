{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/Dr%20Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr Bert\n",
    "Vamos a seguir la tradicción de [ELIZA](https://en.wikipedia.org/wiki/ELIZA) y crear un psicoterapeuta con inteligencia artificial. Vamos a aprovechar la capacidad que tiene el modelo de BERT de reconocer frases consecutivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:12.136533Z",
     "start_time": "2019-08-18T01:13:11.976435Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Nz-PGIg6Jqog",
    "outputId": "6406a04a-e840-419e-c305-cbfed1233ed9"
   },
   "outputs": [],
   "source": [
    "# instalar BERT\n",
    "import sys\n",
    "\n",
    "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
    "if not 'bert_repo' in sys.path:\n",
    "    sys.path += ['bert_repo']\n",
    "\n",
    "# import python modules defined by BERT\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:22.759711Z",
     "start_time": "2019-08-18T01:20:22.753736Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7WAwauYZJqoo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.engine import Layer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import get_file, to_categorical\n",
    "from scipy.special import softmax\n",
    "\n",
    "os.environ['TFHUB_CACHE_DIR'] = './tfhub'\n",
    "checkpoint_dir = 'checkpoints'  #@param {type: \"string\"}\n",
    "limite_de_palabras_en_la_secuencia = 512  #@param {type : \"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:26.306650Z",
     "start_time": "2019-08-18T01:20:26.017706Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zlgbP6BIJqor"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:50.191778Z",
     "start_time": "2019-08-18T01:20:49.160304Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MsAfiBLcJqot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://docs.google.com/uc?export=download&id=1_YRPtRHDmA-Osr4UaVudKMNVEcwsaxU5\n",
      "40960/38421 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "get_file(\n",
    "    os.getcwd() + '/transcript.txt',\n",
    "    origin=\n",
    "    'https://docs.google.com/uc?export=download&id=1_YRPtRHDmA-Osr4UaVudKMNVEcwsaxU5'\n",
    ")\n",
    "with open('transcript.txt', 'rt', encoding='utf-8') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:58.787949Z",
     "start_time": "2019-08-18T01:20:58.784249Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "78SfNtNBJqow"
   },
   "outputs": [],
   "source": [
    "lines = [_.strip()[3:] for _ in lines if len(_) > 1 and _[1] == ':']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:58.800208Z",
     "start_time": "2019-08-18T01:20:58.790040Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CKVD24RtJqo3"
   },
   "outputs": [],
   "source": [
    "data = [(lines[i], lines[i + 1]) for i in range(len(lines) - 1)]\n",
    "random.seed(12345)  # para resultados reproducibles\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:20:59.709597Z",
     "start_time": "2019-08-18T01:20:59.705772Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u1sZ68RpJqo6",
    "outputId": "612ff871-716b-4876-90cf-dfe488aa38cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:21:00.636241Z",
     "start_time": "2019-08-18T01:21:00.632172Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1c80TA91Jqo9",
    "outputId": "9b327e0c-2063-4966-9702-6177c72a7712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Okay.',\n",
       "  'My notes are kept safe, I write very kind of factual notes, so just a kind of very brief description of what we have talked about and any particular issues that come up, and you have access to those notes through me if you want to see them. Otherwise they’re confidential. The only time I would break confidentiality would be if I was seriously concerned about your wellbeing or about the safety and wellbeing of anybody else. Okay?'),\n",
       " ('It feels ... it sort of sits somewhere here (hand to chest), I think. It’s hard to, hard to describe that.',\n",
       "  'Right.'),\n",
       " ('And there might not be a connection.', 'Yeah.')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:22.126898Z",
     "start_time": "2019-08-18T01:13:14.929229Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EgiCpvzWJqo_",
    "outputId": "95ed8d03-32cd-4135-9793-b0f450401da5"
   },
   "outputs": [],
   "source": [
    "modelo_de_bert = 'bert_uncased_L-12_H-768_A-12/1'  #@param [\"bert_uncased_L-12_H-768_A-12/1\", \"bert_cased_L-12_H-768_A-12/1\", \"bert_uncased_L-24_H-1024_A-16/1\", \"bert_cased_L-24_H-1024_A-16/1\", \"bert_multi_cased_L-12_H-768_A-12/1\"]\n",
    "bert = hub.Module('https://tfhub.dev/google/' + modelo_de_bert)\n",
    "\n",
    "# instanciar el tokenizador\n",
    "tokenization_info = bert(signature='tokenization_info', as_dict=True)\n",
    "vocab_file, do_lower_case = sess.run([\n",
    "    tokenization_info['vocab_file'],\n",
    "    tokenization_info['do_lower_case'],\n",
    "])\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file,\n",
    "                                       do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:39.516686Z",
     "start_time": "2019-08-18T01:13:39.501867Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "F2hGtZWfJqpJ"
   },
   "outputs": [],
   "source": [
    "class BertEmbeddingLayer(Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_key='sequence_output',  # 'sequence_output': embedding de las palabras, 'pooled_ouput': embedding de la frase\n",
    "            n_fine_tune_layers=0,  # número de capas a entrenar (sin contar la de pooling)\n",
    "            bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",  # modelo de BERT preentrenado\n",
    "            max_len=512,  # número máximo de tokens en las secuencias\n",
    "            **kwargs):\n",
    "        assert output_key == 'sequence_output' or output_key == 'pooled_output'\n",
    "        super(BertEmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.output_key = output_key\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.bert_path = bert_path\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(self.bert_path,\n",
    "                               trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "        if self.trainable:\n",
    "            if self.output_key == 'pooled_output':\n",
    "                # añadir las variables de la capa de pooling a las que vammos a entrenar\n",
    "                self.trainable_weights += [\n",
    "                    var for var in self.bert.variables if 'pooler/' in var.name\n",
    "                ]\n",
    "            # añadir las variables de las últimas n capas a las que vamos a entrenar\n",
    "            top_layer = max([\n",
    "                int(_[_.find('layer_'):][6:_[_.find('layer_'):].find('/')])\n",
    "                for _ in\n",
    "                [var.name for var in bert.variables if 'layer_' in var.name]\n",
    "            ])\n",
    "            self.trainable_weights += [\n",
    "                var for var in self.bert.variables if any([\n",
    "                    f'layer_{top_layer-i}/' in var.name\n",
    "                    for i in range(self.n_fine_tune_layers)\n",
    "                ])\n",
    "            ]\n",
    "            self.non_trainable_weights += [\n",
    "                var for var in self.bert.variables\n",
    "                if var not in self.trainable_weights\n",
    "            ]\n",
    "        super(BertEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype='int32') for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(input_ids=input_ids,\n",
    "                           input_mask=input_mask,\n",
    "                           segment_ids=segment_ids)\n",
    "        result = self.bert(inputs=bert_inputs,\n",
    "                           signature='tokens',\n",
    "                           as_dict=True)[self.output_key]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.output_key == 'pooled_output':\n",
    "            # embedding de la frase\n",
    "            return (input_shape[0], self.bert.get_output_info_dict('tokens')[\n",
    "                self.output_key].get_shape()[1].value)\n",
    "        else:\n",
    "            # embedding de las palabras\n",
    "            return (input_shape[0], self.max_len,\n",
    "                    self.bert.get_output_info_dict('tokens')[\n",
    "                        self.output_key].get_shape()[2].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:40.566937Z",
     "start_time": "2019-08-18T01:13:40.559319Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ydmCcCSzJqpM"
   },
   "outputs": [],
   "source": [
    "def build_bert_classification_model(\n",
    "        trainable=True,\n",
    "        n_fine_tune_layers=10,\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        max_len=limite_de_palabras_en_la_secuencia,\n",
    "        num_classes=2):\n",
    "    in_id = Input(shape=(max_len, ), name=\"input_ids\")\n",
    "    in_mask = Input(shape=(max_len, ), name=\"input_masks\")\n",
    "    in_segment = Input(shape=(max_len, ), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    embedding = BertEmbeddingLayer(trainable=trainable,\n",
    "                                   output_key='pooled_output',\n",
    "                                   n_fine_tune_layers=n_fine_tune_layers,\n",
    "                                   bert_path=bert_path,\n",
    "                                   max_len=max_len)(bert_inputs)\n",
    "    dropout = Dropout(0.1)(embedding)\n",
    "    pred = Dense(num_classes, activation='sigmoid')(dropout)\n",
    "    model = Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:50.890849Z",
     "start_time": "2019-08-18T01:13:47.180373Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zEzuZnWcJqpR",
    "outputId": "bc1ce390-fcfc-4860-e2d4-6a22574792f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_embedding_layer_9 (BertEmb ((None, 512), 768)   0           input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             ((None, 512), 768)   0           bert_embedding_layer_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                ((None, 512), 2)     1538        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,538\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "entrenable = False  #@param {type : 'boolean'}\n",
    "numero_de_capas_a_tunear = 0  #@param {type: 'slider', min : 0, max : 24}\n",
    "checkpoint_filename = '/DrBertModel.h5'\n",
    "bert_model = build_bert_classification_model(\n",
    "    trainable=entrenable,\n",
    "    n_fine_tune_layers=numero_de_capas_a_tunear,\n",
    "    bert_path='https://tfhub.dev/google/' + modelo_de_bert,\n",
    "    max_len=limite_de_palabras_en_la_secuencia,\n",
    "    num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:22:42.926988Z",
     "start_time": "2019-08-18T01:22:42.924486Z"
    }
   },
   "source": [
    "### Preparar los datos en el formato que espera BERT\n",
    "```python\n",
    "example = [CLS] How are you? [SEP] Fine, thanks [SEP]\n",
    "\n",
    "mask    =   1    1   1   1     1     1     1      1    0 ... 0\n",
    "\n",
    "segment =   0    0   0   0     1     1     1      1    0 ... 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:13:44.093661Z",
     "start_time": "2019-08-18T01:13:43.801292Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SwaDp66xJqpO"
   },
   "outputs": [],
   "source": [
    "train_test_split = 200\n",
    "\n",
    "\n",
    "# generar casos positivos y negativos\n",
    "def get_data(data, max_len):\n",
    "    examples = []\n",
    "    mask = []\n",
    "    segment = []\n",
    "    label = []\n",
    "    for i in range(len(data)):\n",
    "        # consecutivos\n",
    "        q = tokenizer.tokenize(data[i][0])\n",
    "        a = tokenizer.tokenize(data[i][1])\n",
    "        pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
    "        examples.append(\n",
    "            tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
    "                                            ['[SEP]'])[:max_len] + pad)\n",
    "        mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
    "        segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
    "        label.append('1')  # resultado positivo\n",
    "\n",
    "        # no consecutivos\n",
    "        for _ in range(1):\n",
    "            noti = (random.randrange(len(data) - 3) + i + 2) % len(data)\n",
    "            assert (noti < i - 1 or noti > i + 1)\n",
    "            q = tokenizer.tokenize(data[i][0])\n",
    "            a = tokenizer.tokenize(data[noti][1])\n",
    "            pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
    "            examples.append(\n",
    "                tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
    "                                                ['[SEP]'])[:max_len] + pad)\n",
    "            mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
    "            segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
    "            label.append('0')  # resultado negativo\n",
    "    return (np.array(examples), np.array(mask), np.array(segment),\n",
    "            to_categorical(label, 2))\n",
    "\n",
    "\n",
    "train_examples, train_mask, train_segment, train_label = get_data(\n",
    "    data[:train_test_split], limite_de_palabras_en_la_secuencia)\n",
    "test_examples, test_mask, test_segment, test_label = get_data(\n",
    "    data[train_test_split:], limite_de_palabras_en_la_secuencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T00:43:13.751784Z",
     "start_time": "2019-08-18T00:37:02.753325Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-tYnpZmbJqpU",
    "outputId": "3313fb07-9900-42aa-ca15-42a070aeba1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 42 samples\n",
      "Epoch 1/1000\n",
      "400/400 [==============================] - 17s 42ms/step - loss: 0.7676 - acc: 0.5525 - val_loss: 0.6904 - val_acc: 0.4762\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6844 - acc: 0.5425 - val_loss: 0.6856 - val_acc: 0.5476\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6809 - acc: 0.5450 - val_loss: 0.6840 - val_acc: 0.5238\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6848 - acc: 0.5150 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6758 - acc: 0.5725 - val_loss: 0.6823 - val_acc: 0.5000\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6749 - acc: 0.5525 - val_loss: 0.6818 - val_acc: 0.5238\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6732 - acc: 0.5475 - val_loss: 0.6815 - val_acc: 0.5000\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6737 - acc: 0.5600 - val_loss: 0.6796 - val_acc: 0.5000\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6706 - acc: 0.5625 - val_loss: 0.6794 - val_acc: 0.5000\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6766 - acc: 0.5700 - val_loss: 0.6799 - val_acc: 0.4524\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6681 - acc: 0.5800 - val_loss: 0.6795 - val_acc: 0.5000\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6740 - acc: 0.5475 - val_loss: 0.6809 - val_acc: 0.5476\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6724 - acc: 0.5675 - val_loss: 0.6757 - val_acc: 0.4524\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6656 - acc: 0.5600 - val_loss: 0.6779 - val_acc: 0.5476\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6748 - acc: 0.5700 - val_loss: 0.6760 - val_acc: 0.4762\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6698 - acc: 0.5500 - val_loss: 0.6764 - val_acc: 0.5476\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6677 - acc: 0.5475 - val_loss: 0.6746 - val_acc: 0.5476\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6639 - acc: 0.5575 - val_loss: 0.6713 - val_acc: 0.5000\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6703 - acc: 0.5575 - val_loss: 0.6708 - val_acc: 0.5476\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6682 - acc: 0.5700 - val_loss: 0.6736 - val_acc: 0.5238\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6622 - acc: 0.5750 - val_loss: 0.6714 - val_acc: 0.5476\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6657 - acc: 0.5650 - val_loss: 0.6723 - val_acc: 0.5238\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6663 - acc: 0.5275 - val_loss: 0.6711 - val_acc: 0.5000\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6649 - acc: 0.5475 - val_loss: 0.6696 - val_acc: 0.4286\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6674 - acc: 0.5500 - val_loss: 0.6710 - val_acc: 0.5000\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6662 - acc: 0.5300 - val_loss: 0.6680 - val_acc: 0.5000\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6632 - acc: 0.5600 - val_loss: 0.6671 - val_acc: 0.4524\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6709 - acc: 0.5550 - val_loss: 0.6712 - val_acc: 0.5000\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6602 - acc: 0.5550 - val_loss: 0.6656 - val_acc: 0.4524\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6657 - acc: 0.5400 - val_loss: 0.6688 - val_acc: 0.5238\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6686 - acc: 0.5700 - val_loss: 0.6685 - val_acc: 0.4524\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6642 - acc: 0.5600 - val_loss: 0.6785 - val_acc: 0.5952\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6622 - acc: 0.5725 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6590 - acc: 0.5475 - val_loss: 0.6652 - val_acc: 0.5238\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6583 - acc: 0.5275 - val_loss: 0.6633 - val_acc: 0.5476\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6567 - acc: 0.5450 - val_loss: 0.6643 - val_acc: 0.5000\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6567 - acc: 0.5425 - val_loss: 0.6667 - val_acc: 0.4048\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6651 - acc: 0.5350 - val_loss: 0.6616 - val_acc: 0.5000\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6569 - acc: 0.5600 - val_loss: 0.6592 - val_acc: 0.4762\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6566 - acc: 0.5850 - val_loss: 0.6720 - val_acc: 0.5238\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6541 - acc: 0.5700 - val_loss: 0.6650 - val_acc: 0.5238\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6513 - acc: 0.5375 - val_loss: 0.6648 - val_acc: 0.4524\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6540 - acc: 0.5575 - val_loss: 0.6592 - val_acc: 0.5000\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6536 - acc: 0.5575 - val_loss: 0.6633 - val_acc: 0.4762\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6484 - acc: 0.5350 - val_loss: 0.6644 - val_acc: 0.4524\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6535 - acc: 0.5375 - val_loss: 0.6576 - val_acc: 0.5238\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6581 - acc: 0.5425 - val_loss: 0.6654 - val_acc: 0.4524\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6498 - acc: 0.5550 - val_loss: 0.6583 - val_acc: 0.5476\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 7s 18ms/step - loss: 0.6536 - acc: 0.5600 - val_loss: 0.6713 - val_acc: 0.5476\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6598 - acc: 0.5425 - val_loss: 0.6724 - val_acc: 0.4762\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.6539 - acc: 0.5475 - val_loss: 0.6632 - val_acc: 0.5238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5559da2f98>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bert_model.load_weights(checkpoint_dir + checkpoint_filename)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min'),\n",
    "    ModelCheckpoint(checkpoint_dir + checkpoint_filename,\n",
    "                    save_best_only=True,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min')\n",
    "]\n",
    "bert_model.fit(\n",
    "    [train_examples, train_mask, train_segment],\n",
    "    train_label,\n",
    "    validation_data=([test_examples, test_mask, test_segment], test_label),\n",
    "    epochs=1000,\n",
    "    batch_size=32  #@param {type : \"number\"}\n",
    "    #@markdown La memoría utilizada por el GPU depende del tamaño del batch y el número de palabras en las sequencias\n",
    "    ,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T00:00:38.902694Z",
     "start_time": "2019-08-18T00:00:37.840994Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_model.load_weights(checkpoint_dir + checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora podemos empezar la sesión de psicoterapia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T01:00:48.106793Z",
     "start_time": "2019-08-18T00:57:45.309555Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0gTZl7jpJqpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Hi there.\n",
      "Dr Bert: Hi.\n",
      "You: How can you help me with my problem?\n",
      "Dr Bert: Okay, so shall we begin with the issues that you put down on your referral and the issues that you are bringing today. So what’s going on for you?\n",
      "You: Well, I am having panic attacks at work.\n",
      "Dr Bert: I probably ... probably a couple, maybe six weeks ago ... but I see that as quite recent, when I would actually ... I’d get symptoms of, not exactly panic ... I don’t have a panic attack, but I can feel a rising sort of panic here (holds chest)…\n",
      "You: So you suffer from the same thing as me??\n",
      "Dr Bert: Whatever ... does that bring anything up for you, that idea of letting someone down or saying no?\n",
      "You: Um, not really.\n",
      "Dr Bert: Okay, that feels a bit uncomfortable or ...\n",
      "You: So, how do these sessions work exactly?\n",
      "Dr Bert: Okay. The way I work may or may not be different to that so if I just tell you a little bit about the kind of things that I’m interested in and how I imagine the sessions to go. So one of the things is the sessions are 50 minutes long, you don’t need to be worried about the time, that’s my responsibility. But I would like us to meet on a regular basis, and I think in your referral we talked about maybe meeting weekly for say six sessions, six to eight sessions.\n",
      "Dr Bert: Bye!\n"
     ]
    }
   ],
   "source": [
    "max_len = limite_de_palabras_en_la_secuencia\n",
    "try:\n",
    "    while True:\n",
    "        texto = input('You: ')\n",
    "        examples = []\n",
    "        mask = []\n",
    "        segment = []\n",
    "        label = []\n",
    "        for i in range(len(data)):\n",
    "            # consecutivos\n",
    "            q = tokenizer.tokenize(texto)\n",
    "            a = tokenizer.tokenize(data[i][1])\n",
    "            pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
    "            examples.append(\n",
    "                tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
    "                                                ['[SEP]'])[:max_len] + pad)\n",
    "            mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
    "            segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
    "        result = bert_model.predict([examples, mask, segment])\n",
    "        print('Dr Bert: ' + data[np.argmax(softmax(result, axis=1)[:,1])][1])\n",
    "except:\n",
    "    print('Dr Bert: Bye!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Dr Bert.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
