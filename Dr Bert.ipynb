{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dr Bert.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/Dr%20Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02DBl0hJJVMH",
        "colab_type": "text"
      },
      "source": [
        "# Dr Bert\n",
        "Vamos a seguir la tradicción de [ELIZA](https://en.wikipedia.org/wiki/ELIZA) y crear un psicoterapeuta con inteligencia artificial. Vamos a aprovechar la capacidad que tiene el modelo de BERT de reconocer frases consecutivas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNbFebHiJVML",
        "colab_type": "text"
      },
      "source": [
        "### Importar las librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:12.136533Z",
          "start_time": "2019-08-18T01:13:11.976435Z"
        },
        "colab_type": "code",
        "id": "Nz-PGIg6Jqog",
        "outputId": "9f0f7dd8-b713-4329-8bee-a042a1711fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# instalar BERT\n",
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "    sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import tokenization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 279.30 KiB | 1010.00 KiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:22.759711Z",
          "start_time": "2019-08-18T01:20:22.753736Z"
        },
        "colab_type": "code",
        "id": "7WAwauYZJqoo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8cc6e6d-5e77-48fc-80f5-5a21a9a69007"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "import keras.layers as layers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.engine import Layer\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import get_file, to_categorical\n",
        "from scipy.special import softmax\n",
        "\n",
        "os.environ['TFHUB_CACHE_DIR'] = './tfhub'\n",
        "checkpoint_dir = 'checkpoints'  #@param {type: \"string\"}\n",
        "limite_de_palabras_en_la_secuencia = 512  #@param {type : \"number\"}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:26.306650Z",
          "start_time": "2019-08-18T01:20:26.017706Z"
        },
        "colab_type": "code",
        "id": "zlgbP6BIJqor",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J-rSCTNJVMa",
        "colab_type": "text"
      },
      "source": [
        "### Preparamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:50.191778Z",
          "start_time": "2019-08-18T01:20:49.160304Z"
        },
        "colab_type": "code",
        "id": "MsAfiBLcJqot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fd4a17c9-bf92-4e4a-9ee3-15f606004069"
      },
      "source": [
        "get_file(\n",
        "    os.getcwd() + '/transcript.txt',\n",
        "    origin=\n",
        "    'https://docs.google.com/uc?export=download&id=1_YRPtRHDmA-Osr4UaVudKMNVEcwsaxU5'\n",
        ")\n",
        "with open('transcript.txt', 'rt', encoding='utf-8') as file:\n",
        "    lines = file.readlines()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://docs.google.com/uc?export=download&id=1_YRPtRHDmA-Osr4UaVudKMNVEcwsaxU5\n",
            "40960/38421 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:58.787949Z",
          "start_time": "2019-08-18T01:20:58.784249Z"
        },
        "colab_type": "code",
        "id": "78SfNtNBJqow",
        "colab": {}
      },
      "source": [
        "lines = [_.strip()[3:] for _ in lines if len(_) > 1 and _[1] == ':']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:58.800208Z",
          "start_time": "2019-08-18T01:20:58.790040Z"
        },
        "colab_type": "code",
        "id": "CKVD24RtJqo3",
        "colab": {}
      },
      "source": [
        "data = [(lines[i], lines[i + 1]) for i in range(len(lines) - 1)]\n",
        "random.seed(12345)  # para resultados reproducibles\n",
        "random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:20:59.709597Z",
          "start_time": "2019-08-18T01:20:59.705772Z"
        },
        "colab_type": "code",
        "id": "u1sZ68RpJqo6",
        "outputId": "97649bf0-10ae-41ab-9c38-fcfe38627460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:21:00.636241Z",
          "start_time": "2019-08-18T01:21:00.632172Z"
        },
        "colab_type": "code",
        "id": "1c80TA91Jqo9",
        "outputId": "0cfbe9a4-6028-4a38-b700-a33f19b54b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "data[:3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Okay.',\n",
              "  'My notes are kept safe, I write very kind of factual notes, so just a kind of very brief description of what we have talked about and any particular issues that come up, and you have access to those notes through me if you want to see them. Otherwise they’re confidential. The only time I would break confidentiality would be if I was seriously concerned about your wellbeing or about the safety and wellbeing of anybody else. Okay?'),\n",
              " ('It feels ... it sort of sits somewhere here (hand to chest), I think. It’s hard to, hard to describe that.',\n",
              "  'Right.'),\n",
              " ('And there might not be a connection.', 'Yeah.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55I8Dv9aJVMz",
        "colab_type": "text"
      },
      "source": [
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:22.126898Z",
          "start_time": "2019-08-18T01:13:14.929229Z"
        },
        "colab_type": "code",
        "id": "EgiCpvzWJqo_",
        "outputId": "b3ddb560-48d6-46ef-a5fe-841a2dd7c156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "modelo_de_bert = 'bert_uncased_L-12_H-768_A-12/1'  #@param [\"bert_uncased_L-12_H-768_A-12/1\", \"bert_cased_L-12_H-768_A-12/1\", \"bert_uncased_L-24_H-1024_A-16/1\", \"bert_cased_L-24_H-1024_A-16/1\", \"bert_multi_cased_L-12_H-768_A-12/1\"]\n",
        "bert = hub.Module('https://tfhub.dev/google/' + modelo_de_bert)\n",
        "\n",
        "# instanciar el tokenizador\n",
        "tokenization_info = bert(signature='tokenization_info', as_dict=True)\n",
        "vocab_file, do_lower_case = sess.run([\n",
        "    tokenization_info['vocab_file'],\n",
        "    tokenization_info['do_lower_case'],\n",
        "])\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file,\n",
        "                                       do_lower_case=do_lower_case)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 15:21:16.761546 140383545038720 deprecation_wrapper.py:119] From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:39.516686Z",
          "start_time": "2019-08-18T01:13:39.501867Z"
        },
        "colab_type": "code",
        "id": "F2hGtZWfJqpJ",
        "colab": {}
      },
      "source": [
        "class BertEmbeddingLayer(Layer):\n",
        "    def __init__(\n",
        "            self,\n",
        "            output_key='sequence_output',  # 'sequence_output': embedding de las palabras, 'pooled_ouput': embedding de la frase\n",
        "            n_fine_tune_layers=0,  # número de capas a entrenar (sin contar la de pooling)\n",
        "            bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",  # modelo de BERT preentrenado\n",
        "            max_len=512,  # número máximo de tokens en las secuencias\n",
        "            **kwargs):\n",
        "        assert output_key == 'sequence_output' or output_key == 'pooled_output'\n",
        "        super(BertEmbeddingLayer, self).__init__(**kwargs)\n",
        "        self.output_key = output_key\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.bert_path = bert_path\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(self.bert_path,\n",
        "                               trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "        if self.trainable:\n",
        "            if self.output_key == 'pooled_output':\n",
        "                # añadir las variables de la capa de pooling a las que vammos a entrenar\n",
        "                self.trainable_weights += [\n",
        "                    var for var in self.bert.variables if 'pooler/' in var.name\n",
        "                ]\n",
        "            # añadir las variables de las últimas n capas a las que vamos a entrenar\n",
        "            top_layer = max([\n",
        "                int(_[_.find('layer_'):][6:_[_.find('layer_'):].find('/')])\n",
        "                for _ in\n",
        "                [var.name for var in bert.variables if 'layer_' in var.name]\n",
        "            ])\n",
        "            self.trainable_weights += [\n",
        "                var for var in self.bert.variables if any([\n",
        "                    f'layer_{top_layer-i}/' in var.name\n",
        "                    for i in range(self.n_fine_tune_layers)\n",
        "                ])\n",
        "            ]\n",
        "            self.non_trainable_weights += [\n",
        "                var for var in self.bert.variables\n",
        "                if var not in self.trainable_weights\n",
        "            ]\n",
        "        super(BertEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype='int32') for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(input_ids=input_ids,\n",
        "                           input_mask=input_mask,\n",
        "                           segment_ids=segment_ids)\n",
        "        result = self.bert(inputs=bert_inputs,\n",
        "                           signature='tokens',\n",
        "                           as_dict=True)[self.output_key]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.output_key == 'pooled_output':\n",
        "            # embedding de la frase\n",
        "            return (input_shape[0], self.bert.get_output_info_dict('tokens')[\n",
        "                self.output_key].get_shape()[1].value)\n",
        "        else:\n",
        "            # embedding de las palabras\n",
        "            return (input_shape[0], self.max_len,\n",
        "                    self.bert.get_output_info_dict('tokens')[\n",
        "                        self.output_key].get_shape()[2].value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:40.566937Z",
          "start_time": "2019-08-18T01:13:40.559319Z"
        },
        "colab_type": "code",
        "id": "ydmCcCSzJqpM",
        "colab": {}
      },
      "source": [
        "def build_bert_classification_model(\n",
        "        trainable=True,\n",
        "        n_fine_tune_layers=10,\n",
        "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
        "        max_len=limite_de_palabras_en_la_secuencia,\n",
        "        num_classes=2):\n",
        "    in_id = Input(shape=(max_len, ), name=\"input_ids\")\n",
        "    in_mask = Input(shape=(max_len, ), name=\"input_masks\")\n",
        "    in_segment = Input(shape=(max_len, ), name=\"segment_ids\")\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    embedding = BertEmbeddingLayer(trainable=trainable,\n",
        "                                   output_key='pooled_output',\n",
        "                                   n_fine_tune_layers=n_fine_tune_layers,\n",
        "                                   bert_path=bert_path,\n",
        "                                   max_len=max_len)(bert_inputs)\n",
        "    dropout = Dropout(0.1)(embedding)\n",
        "    pred = Dense(num_classes, activation='sigmoid')(dropout)\n",
        "    model = Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:50.890849Z",
          "start_time": "2019-08-18T01:13:47.180373Z"
        },
        "colab_type": "code",
        "id": "zEzuZnWcJqpR",
        "outputId": "58504926-6c70-4718-91a2-2e46b40adedb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "entrenable = False  #@param {type : 'boolean'}\n",
        "numero_de_capas_a_tunear = 0  #@param {type: 'slider', min : 0, max : 24}\n",
        "checkpoint_filename = '/DrBertModel.h5'\n",
        "bert_model = build_bert_classification_model(\n",
        "    trainable=entrenable,\n",
        "    n_fine_tune_layers=numero_de_capas_a_tunear,\n",
        "    bert_path='https://tfhub.dev/google/' + modelo_de_bert,\n",
        "    max_len=limite_de_palabras_en_la_secuencia,\n",
        "    num_classes=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_embedding_layer_2 (BertEmb ((None, 512), 768)   0           input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             ((None, 512), 768)   0           bert_embedding_layer_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 ((None, 512), 2)     1538        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,538\n",
            "Trainable params: 1,538\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:22:42.926988Z",
          "start_time": "2019-08-18T01:22:42.924486Z"
        },
        "id": "tthbs8OpJVNF",
        "colab_type": "text"
      },
      "source": [
        "### Preparar los datos en el formato que espera BERT\n",
        "```python\n",
        "example = [CLS] How are you? [SEP] Fine, thanks [SEP]\n",
        "\n",
        "mask    =   1    1   1   1     1     1     1      1    0 ... 0\n",
        "\n",
        "segment =   0    0   0   0     1     1     1      1    0 ... 0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:13:44.093661Z",
          "start_time": "2019-08-18T01:13:43.801292Z"
        },
        "colab_type": "code",
        "id": "SwaDp66xJqpO",
        "colab": {}
      },
      "source": [
        "train_test_split = 200\n",
        "\n",
        "\n",
        "# generar casos positivos y negativos\n",
        "def get_data(data, max_len):\n",
        "    examples = []\n",
        "    mask = []\n",
        "    segment = []\n",
        "    label = []\n",
        "    for i in range(len(data)):\n",
        "        # consecutivos\n",
        "        q = tokenizer.tokenize(data[i][0])\n",
        "        a = tokenizer.tokenize(data[i][1])\n",
        "        pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
        "        examples.append(\n",
        "            tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
        "                                            ['[SEP]'])[:max_len] + pad)\n",
        "        mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
        "        segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
        "        label.append('1')  # resultado positivo\n",
        "\n",
        "        # no consecutivos\n",
        "        for _ in range(1):\n",
        "            noti = (random.randrange(len(data) - 3) + i + 2) % len(data)\n",
        "            assert (noti < i - 1 or noti > i + 1)\n",
        "            q = tokenizer.tokenize(data[i][0])\n",
        "            a = tokenizer.tokenize(data[noti][1])\n",
        "            pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
        "            examples.append(\n",
        "                tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
        "                                                ['[SEP]'])[:max_len] + pad)\n",
        "            mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
        "            segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
        "            label.append('0')  # resultado negativo\n",
        "    return (np.array(examples), np.array(mask), np.array(segment),\n",
        "            to_categorical(label, 2))\n",
        "\n",
        "\n",
        "train_examples, train_mask, train_segment, train_label = get_data(\n",
        "    data[:train_test_split], limite_de_palabras_en_la_secuencia)\n",
        "test_examples, test_mask, test_segment, test_label = get_data(\n",
        "    data[train_test_split:], limite_de_palabras_en_la_secuencia)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REVyQxOLJVNL",
        "colab_type": "text"
      },
      "source": [
        "### Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T00:43:13.751784Z",
          "start_time": "2019-08-18T00:37:02.753325Z"
        },
        "colab_type": "code",
        "id": "-tYnpZmbJqpU",
        "outputId": "0bb77b99-8d88-4c90-e125-47c301bef5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#bert_model.load_weights(checkpoint_dir + checkpoint_filename)\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min'),\n",
        "#    ModelCheckpoint(checkpoint_dir + checkpoint_filename,\n",
        "#                    save_best_only=True,\n",
        "#                    monitor='val_loss',\n",
        "#                    mode='min')\n",
        "]\n",
        "bert_model.fit(\n",
        "    [train_examples, train_mask, train_segment],\n",
        "    train_label,\n",
        "    validation_data=([test_examples, test_mask, test_segment], test_label),\n",
        "    epochs=1000,\n",
        "    batch_size=32  #@param {type : \"number\"}\n",
        "    #@markdown La memoría utilizada por el GPU depende del tamaño del batch y el número de palabras en las sequencias\n",
        "    ,\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 400 samples, validate on 42 samples\n",
            "Epoch 1/1000\n",
            "400/400 [==============================] - 38s 95ms/step - loss: 0.7191 - acc: 0.4600 - val_loss: 0.6846 - val_acc: 0.5238\n",
            "Epoch 2/1000\n",
            "400/400 [==============================] - 33s 84ms/step - loss: 0.6848 - acc: 0.4850 - val_loss: 0.6888 - val_acc: 0.5714\n",
            "Epoch 3/1000\n",
            "288/400 [====================>.........] - ETA: 8s - loss: 0.6829 - acc: 0.5208 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T00:00:38.902694Z",
          "start_time": "2019-08-18T00:00:37.840994Z"
        },
        "id": "0en1w0NRJVNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model.load_weights(checkpoint_dir + checkpoint_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfI1fyaoJVNV",
        "colab_type": "text"
      },
      "source": [
        "### Ahora podemos empezar la sesión de psicoterapia..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-18T01:00:48.106793Z",
          "start_time": "2019-08-18T00:57:45.309555Z"
        },
        "colab_type": "code",
        "id": "0gTZl7jpJqpd",
        "colab": {},
        "outputId": "f4a1baf8-3749-4f5e-bf1a-92cc4564cf8d"
      },
      "source": [
        "max_len = limite_de_palabras_en_la_secuencia\n",
        "try:\n",
        "    while True:\n",
        "        texto = input('You: ')\n",
        "        examples = []\n",
        "        mask = []\n",
        "        segment = []\n",
        "        label = []\n",
        "        for i in range(len(data)):\n",
        "            # consecutivos\n",
        "            q = tokenizer.tokenize(texto)\n",
        "            a = tokenizer.tokenize(data[i][1])\n",
        "            pad = [0] * (max_len - (len(q) + len(a) + 3))\n",
        "            examples.append(\n",
        "                tokenizer.convert_tokens_to_ids(['[CLS]'] + q + ['[SEP]'] + a +\n",
        "                                                ['[SEP]'])[:max_len] + pad)\n",
        "            mask.append([1] * (len(q) + len(a) + 3) + pad)\n",
        "            segment.append([0] * (len(q) + 2) + [1] * (len(a) + 1) + pad)\n",
        "        result = bert_model.predict([examples, mask, segment])\n",
        "        print('Dr Bert: ' + data[np.argmax(softmax(result, axis=1)[:,1])][1])\n",
        "except:\n",
        "    print('Dr Bert: Bye!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You: Hi there.\n",
            "Dr Bert: Hi.\n",
            "You: How can you help me with my problem?\n",
            "Dr Bert: Okay, so shall we begin with the issues that you put down on your referral and the issues that you are bringing today. So what’s going on for you?\n",
            "You: Well, I am having panic attacks at work.\n",
            "Dr Bert: I probably ... probably a couple, maybe six weeks ago ... but I see that as quite recent, when I would actually ... I’d get symptoms of, not exactly panic ... I don’t have a panic attack, but I can feel a rising sort of panic here (holds chest)…\n",
            "You: So you suffer from the same thing as me??\n",
            "Dr Bert: Whatever ... does that bring anything up for you, that idea of letting someone down or saying no?\n",
            "You: Um, not really.\n",
            "Dr Bert: Okay, that feels a bit uncomfortable or ...\n",
            "You: So, how do these sessions work exactly?\n",
            "Dr Bert: Okay. The way I work may or may not be different to that so if I just tell you a little bit about the kind of things that I’m interested in and how I imagine the sessions to go. So one of the things is the sessions are 50 minutes long, you don’t need to be worried about the time, that’s my responsibility. But I would like us to meet on a regular basis, and I think in your referral we talked about maybe meeting weekly for say six sessions, six to eight sessions.\n",
            "Dr Bert: Bye!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}