{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/BERT_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_qTxZ6ijepG"
   },
   "source": [
    "# Predicir las palabras que faltan en una frase con BERT\n",
    "\n",
    "El entrenamiento de los modelos de BERT pre-entrenados consiste en realizar dos tareas no supervisadas: (1) adivinar las palabras que faltan en una frase y (2) determinar si una frase sigue la otra o no. En este notebook, vamos a poner un modelo pre-entrenado a prueba con la primera tarea.\n",
    "\n",
    "Se puede adaptar para generar frases enteras de texto \"a boleo\". Ver [Bert Babble](https://colab.research.google.com/drive/1MxKZGtQ9SSBjTK5ArsZ5LKhkztzg52RV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cwp7ENpPh7oa"
   },
   "source": [
    "### Descargar el modelo pre-entrenado de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "K5_6isvosq17",
    "outputId": "ce33e48c-045f-47ff-aa16-d00acc87197c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
      "1248387072/1248381879 [==============================] - 6s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./wwm_uncased_L-24_H-1024_A-16.zip'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import get_file\n",
    "\n",
    "# https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
    "# https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "\n",
    "url = 'https://storage.googleapis.com/bert_models/2019_05_30/'  #@param {type : 'string'}\n",
    "modelo = 'wwm_uncased_L-24_H-1024_A-16'  #@param {type : 'string'}\n",
    "get_file(modelo + '.zip',\n",
    "         origin=url + modelo + '.zip',\n",
    "         extract=True,\n",
    "         archive_format=\"zip\",\n",
    "         cache_dir='./',\n",
    "         cache_subdir='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_jboSJ5iGRU"
   },
   "source": [
    "### Instalar e importar BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swIO05WYoRCR"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
    "if not 'bert_repo' in sys.path:\n",
    "    sys.path += ['bert_repo']\n",
    "\n",
    "# import python modules defined by BERT\n",
    "import modeling as tfm\n",
    "import tokenization as tft\n",
    "import run_pretraining as rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ak-H_gGniKrc"
   },
   "source": [
    "### Importar las librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUVxkpNcp68L"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "\n",
    "model_dir = './' + modelo + '/'\n",
    "vocab_file = model_dir + \"vocab.txt\"\n",
    "bert_config_file = model_dir + \"bert_config.json\"\n",
    "init_checkpoint = model_dir + \"bert_model.ckpt\"\n",
    "max_seq_length = 512\n",
    "max_predictions_per_seq = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTGpSyhMiOu4"
   },
   "source": [
    "### Configurar BERT y preparar el tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfYnLriNow1G"
   },
   "outputs": [],
   "source": [
    "convertir_a_minusculas = 'uncased' in modelo\n",
    "bert_config = tfm.BertConfig.from_json_file(bert_config_file)\n",
    "tokenizer = tft.FullTokenizer(vocab_file=vocab_file,\n",
    "                              do_lower_case=convertir_a_minusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnSs2gnNiTn3"
   },
   "source": [
    "### Definir los inputs al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj_uO0uiqRgN"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(name='input_ids',\n",
    "                           shape=(1, max_seq_length),\n",
    "                           dtype='int32')\n",
    "input_mask = tf.placeholder(name='input_mask',\n",
    "                            shape=(1, max_seq_length),\n",
    "                            dtype='int32')\n",
    "segment_ids = tf.placeholder(name='segment_ids',\n",
    "                             shape=(1, max_seq_length),\n",
    "                             dtype='int32')\n",
    "masked_lm_positions = tf.placeholder(name='masked_lm_positions',\n",
    "                                     shape=(1, max_predictions_per_seq),\n",
    "                                     dtype='int32')\n",
    "masked_lm_ids = tf.placeholder(name='masked_lm_ids',\n",
    "                               shape=(1, max_predictions_per_seq),\n",
    "                               dtype='int32')\n",
    "masked_lm_weights = tf.placeholder(name='masked_lm_weights',\n",
    "                                   shape=(1, max_predictions_per_seq),\n",
    "                                   dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZfltyuhiWpH"
   },
   "source": [
    "### Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "Ze-oEVySqWTR",
    "outputId": "ca8a6eb3-6c06-4ef9-ff53-f294925bc6af"
   },
   "outputs": [],
   "source": [
    "model = tfm.BertModel(config=bert_config,\n",
    "                      is_training=False,\n",
    "                      input_ids=input_ids,\n",
    "                      input_mask=input_mask,\n",
    "                      token_type_ids=segment_ids,\n",
    "                      use_one_hot_embeddings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HxpMFB9ViaY4"
   },
   "source": [
    "### Definir los outputs del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiS1PjGYqb1n"
   },
   "outputs": [],
   "source": [
    "(masked_lm_loss, masked_lm_example_loss,\n",
    " masked_lm_log_probs) = rp.get_masked_lm_output(bert_config,\n",
    "                                                model.get_sequence_output(),\n",
    "                                                model.get_embedding_table(),\n",
    "                                                masked_lm_positions,\n",
    "                                                masked_lm_ids,\n",
    "                                                masked_lm_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK2VrPdWif7r"
   },
   "source": [
    "### Inizializar los pesos con el checkpoint del modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWWpoYiLqj7m"
   },
   "outputs": [],
   "source": [
    "(assignment_map,\n",
    " initialized_variable_names) = tfm.get_assignment_map_from_checkpoint(\n",
    "     tf.trainable_variables(), init_checkpoint)\n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTZ9N4qTinuh"
   },
   "source": [
    "### Crear los inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "r-D07YE-pTHl",
    "outputId": "ac6139a7-8410-4fae-f38e-73e5fa485882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orbiting', 'this', 'at', 'a', 'distance', 'of', 'roughly', 'ninety', '-', 'two', 'million', '[MASK]', 'is', 'an', 'utterly', '[MASK]', 'little', 'blue', 'green', '[MASK]', 'whose', 'ape', '-', 'descended', 'life', 'forms', 'are', 'so', 'amazingly', '[MASK]', 'that', 'they', 'still', 'think', '[MASK]', 'watches', 'are', 'a', 'pretty', '[MASK]', 'idea', '.']\n"
     ]
    }
   ],
   "source": [
    "ejemplo = \"Orbiting this at a distance of roughly  ninety-two million miles is  an utterly insignificant little blue green planet whose ape- descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.\"  #@param {type : \"string\"}\n",
    "palabras_a_adivinar = [\n",
    "    'miles', 'insignificant', 'planet', 'neat', 'primitive', 'digital'\n",
    "]  #@param\n",
    "tokens = tokenizer.tokenize(ejemplo)\n",
    "masked_lm_positions_ = positions = [\n",
    "    tokens.index(_) for _ in palabras_a_adivinar if _ in tokens\n",
    "]\n",
    "masked_lm_ids_ = [0] * len(masked_lm_positions_)\n",
    "masked_lm_weights_ = [1.0] * len(masked_lm_positions_)\n",
    "for _ in masked_lm_positions_:\n",
    "    tokens[_] = '[MASK]'\n",
    "input_ids_ = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens)\n",
    "segment_ids_ = [0] * len(input_ids_)\n",
    "input_mask_ = [1] * len(input_ids_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ref2KEEwiuHm"
   },
   "source": [
    "### Hacer que las secuencias tengan el mismo tama√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APowcLPuqOB1"
   },
   "outputs": [],
   "source": [
    "input_ids_ = sequence.pad_sequences([input_ids_],\n",
    "                                    maxlen=max_seq_length,\n",
    "                                    padding='post',\n",
    "                                    value=0)\n",
    "segment_ids_ = sequence.pad_sequences([segment_ids_],\n",
    "                                      maxlen=max_seq_length,\n",
    "                                      padding='post',\n",
    "                                      value=0)\n",
    "input_mask_ = sequence.pad_sequences([input_mask_],\n",
    "                                     maxlen=max_seq_length,\n",
    "                                     padding='post',\n",
    "                                     value=0)\n",
    "masked_lm_positions_ = sequence.pad_sequences([masked_lm_positions_],\n",
    "                                              maxlen=max_predictions_per_seq,\n",
    "                                              padding='post',\n",
    "                                              value=0)\n",
    "masked_lm_ids_ = sequence.pad_sequences([masked_lm_ids_],\n",
    "                                        maxlen=max_predictions_per_seq,\n",
    "                                        padding='post',\n",
    "                                        value=0)\n",
    "masked_lm_weights_ = sequence.pad_sequences([masked_lm_weights_],\n",
    "                                            maxlen=max_predictions_per_seq,\n",
    "                                            padding='post',\n",
    "                                            value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJS0gOzdi3El"
   },
   "source": [
    "### Invocar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF5mor10qmPH"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    matrix = sess.run(masked_lm_log_probs,\n",
    "                      feed_dict={\n",
    "                          input_ids: input_ids_,\n",
    "                          input_mask: input_mask_,\n",
    "                          segment_ids: segment_ids_,\n",
    "                          masked_lm_positions: masked_lm_positions_,\n",
    "                          masked_lm_ids: masked_lm_ids_,\n",
    "                          masked_lm_weights: masked_lm_weights_,\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oeQSI62i_HQ"
   },
   "source": [
    "### Convertir los tokens a texto (las predicciones est√°n en may√∫sculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "lryDHDbKHD03",
    "outputId": "f473f9dc-026a-467a-cbcf-b21b946b2f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orbiting this at a distance of roughly  ninety-two million miles is  an utterly insignificant little blue green planet whose ape- descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.\n",
      "->\n",
      "orbiting this at a distance of roughly ninety-two million KILOMETERS is an utterly PEACEFUL little blue green PLANET whose ape-descended life forms are so amazingly ADVANCED that they still think POCKET watches are a pretty GOOD idea.\n"
     ]
    }
   ],
   "source": [
    "print(ejemplo)\n",
    "print('->')\n",
    "text = ''\n",
    "leave_space = False\n",
    "for i, token in enumerate(tokens):\n",
    "    if i in positions:\n",
    "        token = tokenizer.convert_ids_to_tokens(np.argmax(\n",
    "            matrix, axis=-1))[positions.index(i)].upper()\n",
    "    if token[0:2] == '##':\n",
    "        text += token[2:]\n",
    "    else:\n",
    "        if leave_space and token[0].isalpha():\n",
    "            text += ' '\n",
    "        text += token\n",
    "    leave_space = token[-1] != \"'\" and token[-1] != \"-\"\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
