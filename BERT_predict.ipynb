{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qTxZ6ijepG",
        "colab_type": "text"
      },
      "source": [
        "# Predicir las palabras que faltan en una frase con BERT\n",
        "\n",
        "El entrenamiento de los modelos de BERT pre-entrenados consiste en realizar dos tareas no supervisadas: (1) adivinar las palabras que faltan en una frase y (2) determinar si una frase sigue la otra o no. En este notebook, vamos a poner un modelo pre-entrenado a prueba con la primera tarea.\n",
        "\n",
        "Se puede adaptar para generar frases enteras de texto \"a boleo\". Ver [Bert Babble](https://colab.research.google.com/drive/1MxKZGtQ9SSBjTK5ArsZ5LKhkztzg52RV)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwp7ENpPh7oa",
        "colab_type": "text"
      },
      "source": [
        "### Descargar el modelo pre-entrenado de BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5_6isvosq17",
        "colab_type": "code",
        "outputId": "11c293c8-d450-41e6-f4e3-859c59014e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "# https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
        "\n",
        "url = 'https://storage.googleapis.com/bert_models/2018_11_23/' #@param {type : 'string'}\n",
        "modelo = 'multi_cased_L-12_H-768_A-12' #@param {type : 'string'}\n",
        "command = 'wget '+ url + modelo + '.zip && unzip '+ modelo + '.zip'\n",
        "!{command}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-11 10:33:24--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip.1’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M   158MB/s    in 4.1s    \n",
            "\n",
            "2019-07-11 10:33:28 (154 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip.1’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
            "replace multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jboSJ5iGRU",
        "colab_type": "text"
      },
      "source": [
        "### Instalar e importar BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swIO05WYoRCR",
        "colab_type": "code",
        "outputId": "3ad264dd-2efd-46a6-e5f2-deb5d81d8718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "    sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling as tfm\n",
        "import tokenization as tft\n",
        "import run_pretraining as rp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 10:33:37.661941 140706045007744 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak-H_gGniKrc",
        "colab_type": "text"
      },
      "source": [
        "### Importar las librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUVxkpNcp68L",
        "colab_type": "code",
        "outputId": "d7495e51-a0bd-4fdd-ca4d-8a2f89e529d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "\n",
        "model_dir = './' + modelo +'/'\n",
        "vocab_file = model_dir + \"vocab.txt\"\n",
        "bert_config_file = model_dir + \"bert_config.json\"\n",
        "init_checkpoint = model_dir + \"bert_model.ckpt\"\n",
        "max_seq_length = 512\n",
        "max_predictions_per_seq = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTGpSyhMiOu4",
        "colab_type": "text"
      },
      "source": [
        "### Configurar BERT y preparar el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYnLriNow1G",
        "colab_type": "code",
        "outputId": "6454519f-69ac-4a80-d5e1-e85fe58c14ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "convertir_a_minusculas = 'uncased' in modelo\n",
        "bert_config = tfm.BertConfig.from_json_file(bert_config_file)\n",
        "tokenizer = tft.FullTokenizer(vocab_file=vocab_file, do_lower_case=convertir_a_minusculas)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 10:33:37.750049 140706045007744 deprecation_wrapper.py:119] From bert_repo/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSs2gnNiTn3",
        "colab_type": "text"
      },
      "source": [
        "### Definir los inputs al modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj_uO0uiqRgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = tf.placeholder(name='input_ids', shape=(1, max_seq_length), dtype='int32')\n",
        "input_mask = tf.placeholder(name='input_mask', shape=(1, max_seq_length), dtype='int32')\n",
        "segment_ids = tf.placeholder(name='segment_ids', shape=(1, max_seq_length), dtype='int32')\n",
        "masked_lm_positions = tf.placeholder(name='masked_lm_positions', shape=(1, max_predictions_per_seq), dtype='int32')\n",
        "masked_lm_ids = tf.placeholder(name='masked_lm_ids', shape=(1, max_predictions_per_seq), dtype='int32')\n",
        "masked_lm_weights = tf.placeholder(name='masked_lm_weights', shape=(1, max_predictions_per_seq), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZfltyuhiWpH",
        "colab_type": "text"
      },
      "source": [
        "### Construir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze-oEVySqWTR",
        "colab_type": "code",
        "outputId": "cd7099f8-fc9a-4c56-990d-d9fb67e2d884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model = tfm.BertModel(\n",
        "    config=bert_config,\n",
        "    is_training=False,\n",
        "    input_ids=input_ids,\n",
        "    input_mask=input_mask,\n",
        "    token_type_ids=segment_ids,\n",
        "    use_one_hot_embeddings=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 10:33:38.511967 140706045007744 deprecation_wrapper.py:119] From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0711 10:33:38.519322 140706045007744 deprecation_wrapper.py:119] From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0711 10:33:38.567062 140706045007744 deprecation_wrapper.py:119] From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0711 10:33:40.195948 140706045007744 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0711 10:33:40.244835 140706045007744 deprecation.py:323] From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxpMFB9ViaY4",
        "colab_type": "text"
      },
      "source": [
        "### Definir los outputs del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiS1PjGYqb1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(masked_lm_loss,\n",
        " masked_lm_example_loss, masked_lm_log_probs) = rp.get_masked_lm_output(\n",
        "    bert_config, model.get_sequence_output(), model.get_embedding_table(),\n",
        "    masked_lm_positions, masked_lm_ids, masked_lm_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK2VrPdWif7r",
        "colab_type": "text"
      },
      "source": [
        "### Inizializar los pesos con el checkpoint del modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWpoYiLqj7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(assignment_map,\n",
        " initialized_variable_names) = tfm.get_assignment_map_from_checkpoint(\n",
        "    tf.trainable_variables(), init_checkpoint)\n",
        "tf.train.init_from_checkpoint(init_checkpoint, assignment_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZ9N4qTinuh",
        "colab_type": "text"
      },
      "source": [
        "### Crear los inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-D07YE-pTHl",
        "colab_type": "code",
        "outputId": "1f8c5588-5ccf-4c28-8730-2f2eecc017d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ejemplo = \"Esto es un ejemplo de lo que se puede hacer con BERT. Es capaz de hacer cosas muy interesantes!\" #@param {type : \"string\"}\n",
        "palabras_a_adivinar = ['hacer'] #@param\n",
        "tokens = tokenizer.tokenize(ejemplo)\n",
        "masked_lm_positions_ = [tokens.index(_) for _ in palabras_a_adivinar if _ in tokens]\n",
        "masked_lm_ids_ = [0] * len(masked_lm_positions_)\n",
        "masked_lm_weights_ = [1.0] * len(masked_lm_positions_)\n",
        "for _ in masked_lm_positions_:\n",
        "    tokens[_] = '[MASK]'\n",
        "input_ids_ = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(tokens)\n",
        "segment_ids_ = [0] * len(input_ids_)\n",
        "input_mask_ = [1] * len(input_ids_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Esto', 'es', 'un', 'ejemplo', 'de', 'lo', 'que', 'se', 'puede', '[MASK]', 'con', 'BE', '##RT', '.', 'Es', 'capaz', 'de', 'hacer', 'cosas', 'muy', 'interesante', '##s', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ref2KEEwiuHm",
        "colab_type": "text"
      },
      "source": [
        "### Hacer que las secuencias tengan el mismo tamaño"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APowcLPuqOB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_ = sequence.pad_sequences([input_ids_], maxlen=max_seq_length, padding='post', value=0)\n",
        "segment_ids_ = sequence.pad_sequences([segment_ids_], maxlen=max_seq_length, padding='post', value=0)\n",
        "input_mask_ = sequence.pad_sequences([input_mask_], maxlen=max_seq_length, padding='post', value=0)\n",
        "masked_lm_positions_ = sequence.pad_sequences([masked_lm_positions_], maxlen=max_predictions_per_seq, padding='post', value=0)\n",
        "masked_lm_ids_ = sequence.pad_sequences([masked_lm_ids_], maxlen=max_predictions_per_seq, padding='post', value=0)\n",
        "masked_lm_weights_ = sequence.pad_sequences([masked_lm_weights_], maxlen=max_predictions_per_seq, padding='post', value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJS0gOzdi3El",
        "colab_type": "text"
      },
      "source": [
        "### Invocar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5mor10qmPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    matrix = sess.run(masked_lm_log_probs,\n",
        "                      feed_dict={\n",
        "                          input_ids: input_ids_,\n",
        "                          input_mask: input_mask_,\n",
        "                          segment_ids: segment_ids_,\n",
        "                          masked_lm_positions: masked_lm_positions_,\n",
        "                          masked_lm_ids: masked_lm_ids_,\n",
        "                          masked_lm_weights: masked_lm_weights_,})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oeQSI62i_HQ",
        "colab_type": "text"
      },
      "source": [
        "### Convertir los tokens a texto (las predicciones están en mayúsculas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lryDHDbKHD03",
        "colab_type": "code",
        "outputId": "f9da1ad5-ec3b-4e72-8a60-19069f319d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "i = 0\n",
        "text = ''\n",
        "apostrophe = False\n",
        "for token in tokens:\n",
        "    if token == '[MASK]':\n",
        "        token = tokenizer.convert_ids_to_tokens(np.argmax(matrix, axis=-1))[i].upper()\n",
        "        i += 1\n",
        "    if token[0:2] == '##':\n",
        "        text += token[2:]\n",
        "    else:\n",
        "        if token[0].isalpha() and not apostrophe:\n",
        "            text += ' '\n",
        "        text += token\n",
        "    apostrophe = token[-1] == \"'\"\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Esto es un ejemplo de lo que se puede HACER con BERT. Es capaz de hacer cosas muy interesantes!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}