{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/BERT_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qTxZ6ijepG",
        "colab_type": "text"
      },
      "source": [
        "# Predicir las palabras que faltan en una frase con BERT\n",
        "\n",
        "El entrenamiento de los modelos de BERT pre-entrenados consiste en realizar dos tareas no supervisadas: (1) adivinar las palabras que faltan en una frase y (2) determinar si una frase sigue la otra o no. En este notebook, vamos a poner un modelo pre-entrenado a prueba con la primera tarea.\n",
        "\n",
        "Se puede adaptar para generar frases enteras de texto \"a boleo\". Ver [Bert Babble](https://colab.research.google.com/drive/1MxKZGtQ9SSBjTK5ArsZ5LKhkztzg52RV)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwp7ENpPh7oa",
        "colab_type": "text"
      },
      "source": [
        "### Descargar el modelo pre-entrenado de BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5_6isvosq17",
        "colab_type": "code",
        "outputId": "ce33e48c-045f-47ff-aa16-d00acc87197c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from keras.utils import get_file\n",
        "\n",
        "# https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "# https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
        "\n",
        "url = 'https://storage.googleapis.com/bert_models/2019_05_30/' #@param {type : 'string'}\n",
        "modelo = 'wwm_uncased_L-24_H-1024_A-16' #@param {type : 'string'}\n",
        "get_file(modelo + '.zip', origin=url + modelo + '.zip', extract=True, archive_format=\"zip\", cache_dir='./', cache_subdir='')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
            "1248387072/1248381879 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./wwm_uncased_L-24_H-1024_A-16.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jboSJ5iGRU",
        "colab_type": "text"
      },
      "source": [
        "### Instalar e importar BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swIO05WYoRCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "    sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling as tfm\n",
        "import tokenization as tft\n",
        "import run_pretraining as rp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak-H_gGniKrc",
        "colab_type": "text"
      },
      "source": [
        "### Importar las librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUVxkpNcp68L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "\n",
        "model_dir = './' + modelo +'/'\n",
        "vocab_file = model_dir + \"vocab.txt\"\n",
        "bert_config_file = model_dir + \"bert_config.json\"\n",
        "init_checkpoint = model_dir + \"bert_model.ckpt\"\n",
        "max_seq_length = 512\n",
        "max_predictions_per_seq = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTGpSyhMiOu4",
        "colab_type": "text"
      },
      "source": [
        "### Configurar BERT y preparar el tokenizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYnLriNow1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convertir_a_minusculas = 'uncased' in modelo\n",
        "bert_config = tfm.BertConfig.from_json_file(bert_config_file)\n",
        "tokenizer = tft.FullTokenizer(vocab_file=vocab_file, do_lower_case=convertir_a_minusculas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSs2gnNiTn3",
        "colab_type": "text"
      },
      "source": [
        "### Definir los inputs al modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj_uO0uiqRgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = tf.placeholder(name='input_ids', shape=(1, max_seq_length), dtype='int32')\n",
        "input_mask = tf.placeholder(name='input_mask', shape=(1, max_seq_length), dtype='int32')\n",
        "segment_ids = tf.placeholder(name='segment_ids', shape=(1, max_seq_length), dtype='int32')\n",
        "masked_lm_positions = tf.placeholder(name='masked_lm_positions', shape=(1, max_predictions_per_seq), dtype='int32')\n",
        "masked_lm_ids = tf.placeholder(name='masked_lm_ids', shape=(1, max_predictions_per_seq), dtype='int32')\n",
        "masked_lm_weights = tf.placeholder(name='masked_lm_weights', shape=(1, max_predictions_per_seq), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZfltyuhiWpH",
        "colab_type": "text"
      },
      "source": [
        "### Construir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze-oEVySqWTR",
        "colab_type": "code",
        "outputId": "ca8a6eb3-6c06-4ef9-ff53-f294925bc6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "model = tfm.BertModel(config=bert_config,\n",
        "                      is_training=False,\n",
        "                      input_ids=input_ids,\n",
        "                      input_mask=input_mask,\n",
        "                      token_type_ids=segment_ids,\n",
        "                      use_one_hot_embeddings=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0816 14:47:27.435554 140376845076352 deprecation_wrapper.py:119] From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0816 14:47:27.452529 140376845076352 deprecation_wrapper.py:119] From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0816 14:47:27.479144 140376845076352 deprecation_wrapper.py:119] From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0816 14:47:30.494494 140376845076352 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0816 14:47:30.522352 140376845076352 deprecation.py:323] From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxpMFB9ViaY4",
        "colab_type": "text"
      },
      "source": [
        "### Definir los outputs del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiS1PjGYqb1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(masked_lm_loss,\n",
        " masked_lm_example_loss, masked_lm_log_probs) = rp.get_masked_lm_output(\n",
        "    bert_config, model.get_sequence_output(), model.get_embedding_table(),\n",
        "    masked_lm_positions, masked_lm_ids, masked_lm_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK2VrPdWif7r",
        "colab_type": "text"
      },
      "source": [
        "### Inizializar los pesos con el checkpoint del modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWpoYiLqj7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(assignment_map,\n",
        " initialized_variable_names) = tfm.get_assignment_map_from_checkpoint(\n",
        "    tf.trainable_variables(), init_checkpoint)\n",
        "tf.train.init_from_checkpoint(init_checkpoint, assignment_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZ9N4qTinuh",
        "colab_type": "text"
      },
      "source": [
        "### Crear los inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-D07YE-pTHl",
        "colab_type": "code",
        "outputId": "ac6139a7-8410-4fae-f38e-73e5fa485882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "ejemplo = \"Orbiting this at a distance of roughly  ninety-two million miles is  an utterly insignificant little blue green planet whose ape- descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.\" #@param {type : \"string\"}\n",
        "palabras_a_adivinar = ['miles', 'insignificant', 'planet', 'neat', 'primitive', 'digital'] #@param\n",
        "tokens = tokenizer.tokenize(ejemplo)\n",
        "masked_lm_positions_ = positions = [tokens.index(_) for _ in palabras_a_adivinar if _ in tokens]\n",
        "masked_lm_ids_ = [0] * len(masked_lm_positions_)\n",
        "masked_lm_weights_ = [1.0] * len(masked_lm_positions_)\n",
        "for _ in masked_lm_positions_:\n",
        "    tokens[_] = '[MASK]'\n",
        "input_ids_ = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(tokens)\n",
        "segment_ids_ = [0] * len(input_ids_)\n",
        "input_mask_ = [1] * len(input_ids_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['orbiting', 'this', 'at', 'a', 'distance', 'of', 'roughly', 'ninety', '-', 'two', 'million', '[MASK]', 'is', 'an', 'utterly', '[MASK]', 'little', 'blue', 'green', '[MASK]', 'whose', 'ape', '-', 'descended', 'life', 'forms', 'are', 'so', 'amazingly', '[MASK]', 'that', 'they', 'still', 'think', '[MASK]', 'watches', 'are', 'a', 'pretty', '[MASK]', 'idea', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ref2KEEwiuHm",
        "colab_type": "text"
      },
      "source": [
        "### Hacer que las secuencias tengan el mismo tama√±o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APowcLPuqOB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_ = sequence.pad_sequences([input_ids_], maxlen=max_seq_length, padding='post', value=0)\n",
        "segment_ids_ = sequence.pad_sequences([segment_ids_], maxlen=max_seq_length, padding='post', value=0)\n",
        "input_mask_ = sequence.pad_sequences([input_mask_], maxlen=max_seq_length, padding='post', value=0)\n",
        "masked_lm_positions_ = sequence.pad_sequences([masked_lm_positions_], maxlen=max_predictions_per_seq, padding='post', value=0)\n",
        "masked_lm_ids_ = sequence.pad_sequences([masked_lm_ids_], maxlen=max_predictions_per_seq, padding='post', value=0)\n",
        "masked_lm_weights_ = sequence.pad_sequences([masked_lm_weights_], maxlen=max_predictions_per_seq, padding='post', value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJS0gOzdi3El",
        "colab_type": "text"
      },
      "source": [
        "### Invocar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5mor10qmPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    matrix = sess.run(masked_lm_log_probs,\n",
        "                      feed_dict={\n",
        "                          input_ids: input_ids_,\n",
        "                          input_mask: input_mask_,\n",
        "                          segment_ids: segment_ids_,\n",
        "                          masked_lm_positions: masked_lm_positions_,\n",
        "                          masked_lm_ids: masked_lm_ids_,\n",
        "                          masked_lm_weights: masked_lm_weights_,})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oeQSI62i_HQ",
        "colab_type": "text"
      },
      "source": [
        "### Convertir los tokens a texto (las predicciones est√°n en may√∫sculas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lryDHDbKHD03",
        "colab_type": "code",
        "outputId": "f473f9dc-026a-467a-cbcf-b21b946b2f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(ejemplo)\n",
        "print('->')\n",
        "text = ''\n",
        "leave_space = False\n",
        "for i, token in enumerate(tokens):\n",
        "    if i in positions:\n",
        "        token = tokenizer.convert_ids_to_tokens(np.argmax(matrix, axis=-1))[positions.index(i)].upper()\n",
        "    if token[0:2] == '##':\n",
        "        text += token[2:]\n",
        "    else:\n",
        "        if leave_space and token[0].isalpha():\n",
        "            text += ' '\n",
        "        text += token\n",
        "    leave_space = token[-1] != \"'\" and token[-1] != \"-\"\n",
        "print(text)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Orbiting this at a distance of roughly  ninety-two million miles is  an utterly insignificant little blue green planet whose ape- descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.\n",
            "->\n",
            "orbiting this at a distance of roughly ninety-two million KILOMETERS is an utterly PEACEFUL little blue green PLANET whose ape-descended life forms are so amazingly ADVANCED that they still think POCKET watches are a pretty GOOD idea.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrZXWsvDWxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}