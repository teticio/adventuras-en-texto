{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/BERT_entiende.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_qTxZ6ijepG",
    "lang": "es"
   },
   "source": [
    "# Contestar preguntas sobre un texto\n",
    "\n",
    "BERT ha conseguido resultados del estado del arte en la tarea de SQuAD (Stanford Question Answering Dataset), que consiste en indentificar la sección de un texto que corresponda a una pregunta.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "Q: *Where do water droplets collide with ice crystals to form precipitation?*\n",
    "\n",
    "A: In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals **within a cloud**. Short, intense periods of rain in scattered locations are called “showers”.\n",
    "\n",
    "Vamos a usar un modelo que ha sido fine-tuneado con esta tarea para contestar preguntas sobre textos en general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HO7ipdfBJ6lr",
    "lang": "en"
   },
   "source": [
    "# Answer questions about a text\n",
    "\n",
    "BERT has acheived state of the art results in the SQuAD task (Stanford Question Answering Dataset), which consists of identifying the section of a text that corresponds to a question.\n",
    "\n",
    "For example:\n",
    "\n",
    "Q: *Where do water droplets collide with ice crystals to form precipitation?*\n",
    "\n",
    "A: In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals **within a cloud**. Short, intense periods of rain in scattered locations are called “showers”.\n",
    "\n",
    "We are going to use a model that has been fine-tuned with the task to answer general questions about texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cwp7ENpPh7oa",
    "lang": "es"
   },
   "source": [
    "### Descargar el modelo de BERT pre-entrenado con SQUAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vabe5dhJJ6lu",
    "lang": "en"
   },
   "source": [
    "### Download the BERT model pre-trained with SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:07:09.253884Z",
     "start_time": "2019-10-02T18:05:23.405533Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "K5_6isvosq17",
    "outputId": "751cf56c-7390-44e1-b89d-7336e6afc8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-02 20:05:23--  https://s3.eu-west-2.amazonaws.com/nlpfiles/squad_bert_base.tgz\n",
      "Resolving s3.eu-west-2.amazonaws.com (s3.eu-west-2.amazonaws.com)... 52.95.148.56\n",
      "Connecting to s3.eu-west-2.amazonaws.com (s3.eu-west-2.amazonaws.com)|52.95.148.56|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1313280000 (1,2G) [application/x-compressed]\n",
      "Saving to: ‘squad_bert_base.tgz’\n",
      "\n",
      "squad_bert_base.tgz 100%[===================>]   1,22G  11,9MB/s    in 1m 45s  \n",
      "\n",
      "2019-10-02 20:07:08 (12,0 MB/s) - ‘squad_bert_base.tgz’ saved [1313280000/1313280000]\n",
      "\n",
      "squad_bert_base/\n",
      "squad_bert_base/bert_config.json\n",
      "squad_bert_base/model.ckpt-14599.meta\n",
      "squad_bert_base/vocab.txt\n",
      "squad_bert_base/model.ckpt-14599.data-00000-of-00001\n",
      "squad_bert_base/model.ckpt-14599.index\n"
     ]
    }
   ],
   "source": [
    "# de https://github.com/Maaarcocr\n",
    "!test -f squad_bert_base.tgz || wget https://s3.eu-west-2.amazonaws.com/nlpfiles/squad_bert_base.tgz\n",
    "!test -e squad_bert_base || tar -xvf squad_bert_base.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_jboSJ5iGRU",
    "lang": "es"
   },
   "source": [
    "### Instalar e importar BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmOtuDaAJ6l4",
    "lang": "en"
   },
   "source": [
    "### Install and import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:11.623982Z",
     "start_time": "2019-10-02T18:22:10.475676Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "swIO05WYoRCR",
    "outputId": "84ff61b7-567a-4b74-af8b-e94da084db6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1002 20:22:11.620714 140572954515264 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
    "if not 'bert_repo' in sys.path:\n",
    "    sys.path += ['bert_repo']\n",
    "\n",
    "# import python modules defined by BERT\n",
    "import modeling as tfm\n",
    "import tokenization as tft\n",
    "import run_squad as rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ak-H_gGniKrc",
    "lang": "es"
   },
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmFCCOlFJ6mB",
    "lang": "en"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:12.432124Z",
     "start_time": "2019-10-02T18:22:12.407267Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eUVxkpNcp68L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import get_file\n",
    "from scipy.special import softmax\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "model_dir = './squad_bert_base/'\n",
    "vocab_file = model_dir + \"vocab.txt\"\n",
    "bert_config_file = model_dir + \"bert_config.json\"\n",
    "init_checkpoint = model_dir + \"model.ckpt-14599\"\n",
    "max_seq_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTGpSyhMiOu4",
    "lang": "es"
   },
   "source": [
    "### Configurar BERT y preparar el tokenizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edQSyxvdJ6mI",
    "lang": "en"
   },
   "source": [
    "### Configure BERT and prepare the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:14.039914Z",
     "start_time": "2019-10-02T18:22:13.977131Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QfYnLriNow1G",
    "outputId": "2ff27d77-2775-4c3c-f851-45fa99258a2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1002 20:22:13.978984 140572954515264 deprecation_wrapper.py:119] From bert_repo/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to lower case?\n",
    "convertir_a_minusculas = True\n",
    "bert_config = tfm.BertConfig.from_json_file(bert_config_file)\n",
    "tokenizer = tft.FullTokenizer(vocab_file=vocab_file,\n",
    "                              do_lower_case=convertir_a_minusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnSs2gnNiTn3",
    "lang": "es"
   },
   "source": [
    "### Definir los inputs al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFNTunVoJ6mU",
    "lang": "en"
   },
   "source": [
    "### Define the inputs to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:27.042516Z",
     "start_time": "2019-10-02T18:22:27.023143Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hj_uO0uiqRgN"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(name='input_ids',\n",
    "                           shape=(None, max_seq_length),\n",
    "                           dtype='int32')\n",
    "input_mask = tf.placeholder(name='input_mask',\n",
    "                            shape=(None, max_seq_length),\n",
    "                            dtype='int32')\n",
    "segment_ids = tf.placeholder(name='segment_ids',\n",
    "                             shape=(None, max_seq_length),\n",
    "                             dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZfltyuhiWpH",
    "lang": "es"
   },
   "source": [
    "### Construir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io5QRsYLJ6mj",
    "lang": "en"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:31.940465Z",
     "start_time": "2019-10-02T18:22:29.876208Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l3GWdOOUJ6md"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1002 20:22:29.883412 140572954515264 deprecation_wrapper.py:119] From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1002 20:22:29.885444 140572954515264 deprecation_wrapper.py:119] From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W1002 20:22:29.904827 140572954515264 deprecation_wrapper.py:119] From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W1002 20:22:30.373260 140572954515264 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1002 20:22:30.400531 140572954515264 deprecation.py:323] From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "(start_logits, end_logits) = rs.create_model(bert_config=bert_config,\n",
    "                                             is_training=False,\n",
    "                                             input_ids=input_ids,\n",
    "                                             input_mask=input_mask,\n",
    "                                             segment_ids=segment_ids,\n",
    "                                             use_one_hot_embeddings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK2VrPdWif7r",
    "lang": "es"
   },
   "source": [
    "### Inizializar los pesos con el checkpoint del modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dmHJRhtJ6mn",
    "lang": "en"
   },
   "source": [
    "### Initialize the weights with the checkpoint of the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:22:33.222766Z",
     "start_time": "2019-10-02T18:22:32.863907Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SWWpoYiLqj7m"
   },
   "outputs": [],
   "source": [
    "(assignment_map,\n",
    " initialized_variable_names) = tfm.get_assignment_map_from_checkpoint(\n",
    "     tf.trainable_variables(), init_checkpoint)\n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTZ9N4qTinuh",
    "lang": "es"
   },
   "source": [
    "### Crear los inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ti2nDWgQJ6mv",
    "lang": "en"
   },
   "source": [
    "### Create the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:33:36.081010Z",
     "start_time": "2019-10-02T18:33:36.068879Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r-D07YE-pTHl"
   },
   "outputs": [],
   "source": [
    "# context\n",
    "contexto = \"In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called “showers”.\"  #@param {type : \"string\"}\n",
    "# question\n",
    "pregunta = \"Where do water droplets collide with ice crystals to form precipitation?\"  #@param {type : \"string\"}\n",
    "tokens = ['[CLS]'] + tokenizer.tokenize(pregunta) + ['[SEP]'] + tokenizer.tokenize(contexto) + ['[SEP]']\n",
    "input_ids_ = tokenizer.convert_tokens_to_ids(tokens)\n",
    "len_seg = tokens.index('[SEP]') + 1\n",
    "segment_ids_ = [0] * len_seg + [1] * (len(input_ids_) - len_seg)\n",
    "input_mask_ = [1] * len(input_ids_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ref2KEEwiuHm",
    "lang": "es"
   },
   "source": [
    "### Hacer que las secuencias tengan el mismo tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVjUS732J6m7",
    "lang": "en"
   },
   "source": [
    "### Make sequences the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:33:37.030366Z",
     "start_time": "2019-10-02T18:33:37.025687Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "APowcLPuqOB1"
   },
   "outputs": [],
   "source": [
    "input_ids_ = sequence.pad_sequences([input_ids_],\n",
    "                                    maxlen=max_seq_length,\n",
    "                                    padding='post',\n",
    "                                    value=0)\n",
    "segment_ids_ = sequence.pad_sequences([segment_ids_],\n",
    "                                      maxlen=max_seq_length,\n",
    "                                      padding='post',\n",
    "                                      value=0)\n",
    "input_mask_ = sequence.pad_sequences([input_mask_],\n",
    "                                     maxlen=max_seq_length,\n",
    "                                     padding='post',\n",
    "                                     value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJS0gOzdi3El",
    "lang": "es"
   },
   "source": [
    "### Invocar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZK7ZqI0J6nC",
    "lang": "en"
   },
   "source": [
    "### Invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:33:38.681586Z",
     "start_time": "2019-10-02T18:33:37.879751Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mF5mor10qmPH"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tup = sess.run(\n",
    "        (start_logits, end_logits),\n",
    "        feed_dict={\n",
    "            input_ids: input_ids_,\n",
    "            input_mask: input_mask_,\n",
    "            segment_ids: segment_ids_,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:33:38.685646Z",
     "start_time": "2019-10-02T18:33:38.683533Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rOR7lRayJ6nP"
   },
   "outputs": [],
   "source": [
    "start = np.argmax(tup[0])\n",
    "end = np.argmax(tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oeQSI62i_HQ",
    "lang": "es"
   },
   "source": [
    "### Convertir los tokens a texto (las predicciones están en mayúsculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7JNUrdqJ6nb",
    "lang": "en"
   },
   "source": [
    "### Convert tokens to text (predictions are in uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:33:40.015429Z",
     "start_time": "2019-10-02T18:33:40.007815Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "lryDHDbKHD03",
    "outputId": "3aa031de-30e7-42b5-8b1d-a2d6b1e118b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>where do water droplets collide with ice crystals to form precipitation? in meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. the main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals<b> within a cloud</b>. short, intense periods of rain in scattered locations are called“ showers”.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = '<p>'\n",
    "leave_space = False\n",
    "for i, token in enumerate(tokens):\n",
    "    if i == start:\n",
    "        text += \"<b>\"\n",
    "    if i == end + 1:\n",
    "        text += \"</b>\"\n",
    "    if token == '[CLS]' or token == '[SEP]':\n",
    "        continue\n",
    "    if token[0:2] == '##':\n",
    "        text += token[2:]\n",
    "    else:\n",
    "        if leave_space and token[0].isalnum():\n",
    "            text += ' '\n",
    "        text += token\n",
    "    leave_space = token[-1] != \"'\" and token[-1] != \"-\"\n",
    "text += '</p>'\n",
    "display(HTML(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giJTEqaORM_l",
    "lang": "es"
   },
   "source": [
    "### Ahora buscamos la respuesta a una pregunta en un texto más largo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Now let's look for the answer to a question in a longer text ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:08:42.640968Z",
     "start_time": "2019-10-02T18:08:40.750938Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0o-fw7rUJ6nk",
    "outputId": "73e039c2-b4ab-476b-91dd-95d943dcc4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://docs.google.com/uc?export=download&id=10OhbIQHNJrtBiKer8tP_LbxjASqItNzZ\n",
      "1204224/1198109 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/teticio/ML/aventuras-con-textos/example.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Harry Potter and the Goblet of Fire\n",
    "get_file(\n",
    "    os.getcwd() + '/example.txt',\n",
    "    origin=\n",
    "    'https://docs.google.com/uc?export=download&id=10OhbIQHNJrtBiKer8tP_LbxjASqItNzZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:15:19.298746Z",
     "start_time": "2019-10-02T20:15:19.280724Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vB0O4_U6PqD_"
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "with open(os.getcwd() + '/example.txt', 'rt') as file:\n",
    "    for line in file.readlines():\n",
    "        text += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:15:22.385605Z",
     "start_time": "2019-10-02T20:15:19.919376Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8FjxphynRyF2"
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:24:38.791752Z",
     "start_time": "2019-10-02T20:24:38.789185Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NZKdMKB0Q5Wy"
   },
   "outputs": [],
   "source": [
    "pregunta = \"Where does Harry go to school?\"  #@param {type : \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:25:36.805946Z",
     "start_time": "2019-10-02T20:24:38.793530Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "RXrYGhDeSlw1",
    "outputId": "a08439b3-c72e-4cb5-d82c-d17644eefa8c"
   },
   "outputs": [],
   "source": [
    "batch_size = 32  #@param {'type' : 'integer'}\n",
    "q = tokenizer.tokenize(pregunta)\n",
    "chunk_size = max_seq_length - 3 - len(q)\n",
    "results = []\n",
    "\n",
    "input_ids_ = [None] * batch_size\n",
    "segment_ids_ = [None] * batch_size\n",
    "input_mask_ = [None] * batch_size\n",
    "index = [None] * batch_size\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(tokens), chunk_size - chunk_size // 2):\n",
    "    if i + chunk_size > len(tokens):  # último batch\n",
    "        # last batch\n",
    "        i = len(tokens) - chunk_size\n",
    "\n",
    "    chunk = ['[CLS]'] + q + ['[SEP]'] + tokens[i:i + chunk_size] + ['[SEP]']\n",
    "    input_ids_[j] = tokenizer.convert_tokens_to_ids(chunk)\n",
    "    len_seg = chunk.index('[SEP]') + 1\n",
    "    segment_ids_[j] = [0] * len_seg + [1] * (len(input_ids_[j]) - len_seg)\n",
    "    input_mask_[j] = [1] * len(input_ids_[j])\n",
    "    index[j] = i\n",
    "\n",
    "    if i + chunk_size > len(tokens):  # último batch\n",
    "        # last batch\n",
    "        for j in range(j, batch_size):\n",
    "            input_ids_[j] = np.zeros(max_seq_length)\n",
    "            segment_ids_[j] = np.zeros(max_seq_length)\n",
    "            input_mask_[j] = np.zeros(max_seq_length)\n",
    "\n",
    "    if j == batch_size - 1:\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            tup = sess.run(\n",
    "                (start_logits, end_logits),\n",
    "                feed_dict={\n",
    "                    input_ids: np.vstack(input_ids_),\n",
    "                    input_mask: np.vstack(input_mask_),\n",
    "                    segment_ids: np.vstack(segment_ids_),\n",
    "                })\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            prob = np.max(softmax(tup[0][_])) * np.max(softmax(tup[1][_]))\n",
    "            start = np.argmax(tup[0][_])\n",
    "            end = np.argmax(tup[1][_])\n",
    "            if (start > 0 or end > 0):\n",
    "                results += [(prob, index[_], start, end)]\n",
    "\n",
    "    j += 1\n",
    "    if j >= batch_size:\n",
    "        j = 0\n",
    "\n",
    "results = sorted(results, key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T20:25:36.815103Z",
     "start_time": "2019-10-02T20:25:36.807299Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "MlM5VapOVrC8",
    "outputId": "42fb4b86-97ea-4e60-a633-487829c212c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><i>Where does Harry go to school?</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>[0.99] <b>north tower</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>[0.75] <b>hogwarts</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>[0.71] <b>hogwarts school</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>[0.59] <b>dark arts classroom</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>[0.55] <b>dormitory</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<p><i>' + pregunta + '</i></p>'))\n",
    "for i in range(min(len(results), 5)):\n",
    "    text = f'<p>[{results[i][0]:.2f}] <b>'\n",
    "    leave_space = False\n",
    "    for token in tokens[results[i][1] + results[i][2] - len(q) -\n",
    "                        2:results[i][1] + results[i][3] + 1 - len(q) - 2]:\n",
    "        if token[0:2] == '##':\n",
    "            text += token[2:]\n",
    "        else:\n",
    "            if leave_space and token[0].isalnum():\n",
    "                text += ' '\n",
    "            text += token\n",
    "        leave_space = token[-1] != \"'\" and token[-1] != \"-\"\n",
    "    text += '</b></p>'\n",
    "    display(HTML(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT predict.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
