{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/teticio/aventuras-con-textos/blob/master/Modelos_generativos_de_texto_de_%C3%BAltima_generaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T25DUNWU0R7t"
   },
   "source": [
    "# Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:28:18.911493Z",
     "start_time": "2019-08-17T08:28:18.907061Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zZq-8euV0Q-f",
    "outputId": "03868030-c2c4-47c1-d527-1de89e058972"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import subprocess as sp\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import get_file\n",
    "\n",
    "checkpoint_dir = os.getcwd().replace('\\\\', '/') + '/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4eQ2KGyPgUx"
   },
   "source": [
    "# XLNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EItLO1rwgd9Y"
   },
   "source": [
    "### Instalar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Sg2zUAnoZ_IK",
    "outputId": "92fd654d-e072-4549-c9eb-0a753a0ab719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.0MB 6.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 19.7MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!test -d XLnet-gen || git clone --quiet https://github.com/rusiaaman/XLnet-gen.git\n",
    "!pip install -q -r XLnet-gen/requirements.txt\n",
    "!test -e cased_L-24_H-1024_A-16.zip || wget -q https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
    "!test -d xlnet_cased_L-24_H-1024_A-16 || unzip -q cased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xq_iYW7ogjw7"
   },
   "source": [
    "### Generar texto\n",
    "\n",
    "Requiere `pip install tensorflow==1.14.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "2JBzCdVv6Q-z",
    "outputId": "0787d36c-b9a0-4e19-c551-f8b826052f1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======Example 0=================\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Sadly, however, before she could get to a phone to tell anyone- about it, a terribly stupid catastrophe occurred, and the idea was lost forever.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======Example 0 SAMPLE 0======\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Now she was stuck with the dreadful notion of seeing herself impure and not even knowing what she had imagined. Sure, it was only a whiff of impure air she had been breathing for that whole time, but what could she have actually imagined? She had no idea how to think of anything.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>After everyone had spoken, she turned to take the stairs down to her apartment and watched the people leave. The crowd were already in a hurry to get out of the restaurant. Since she was alone, she thought she would try to a lie. With each successive thing she wanted to tell people, she found it hard to think of a lie.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>A big pro at lying like her father was, she needed to think of something else that would have an easy target in the eyes of those around her. After all, this was her last chance to tell her father about her friend and everyone else about her boyfriend and the wedding plans they had on the horizon. At the moment, it was more important to avoid things than face her fears.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>For that reason, she started to think about something else. Possibly something that would involve going to a dungeon, torture, or some other horrible horrible thing that would hurt her. It would also need to be intimate with people, which her father would probably be very uncomfortable with. When she thought about the possibility, she was appalled by how terribly destructive and scary it all could be.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Next, she thought about another rather horrible idea that was \"on the thoughts\" of the other people in the restaurant. These men were already together. She decided it would be easy for them to discover that there were two women in the party, and take their chances with them. She knew she could prevent this. In fact, she was preparing herself mentally to use her abilities to prevent it. If anything, it might also make things even more difficult for her dad.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>She thought about how hard it was not to see herself in the same light as the woman who had been in the photo. In fact, it was hard to imagine the woman as the person who had been in the photo, because she had no idea what it would be like. It seemed much more difficult than she had thought it would be.\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>She had to have some kind of defense for herself. If anyone did discover that she was a female, it would mean a lot to her father. The thought of that made her want to scream, but the words didn't come easily to her. They didn't come\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>==================================\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo = 'Sadly, however, before she could get to a phone to tell anyone- about it, a terribly stupid catastrophe occurred, and the idea was lost forever.'  #@param {type : 'string'}\n",
    "with open('test', 'wt') as file:\n",
    "    file.write(ejemplo)\n",
    "command = [\n",
    "    sys.executable, 'XLnet-gen/language_generation.py',\n",
    "    '--model_config_path=xlnet_cased_L-24_H-1024_A-16/xlnet_config.json',\n",
    "    '--init_checkpoint=xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt',\n",
    "    '--spiece_model_file=xlnet_cased_L-24_H-1024_A-16/spiece.model',\n",
    "    '--input_file=test', '--max_mem_length=512', '--num_toks_pred=512',\n",
    "    '--num_samples=1', '--top_p=0.9'\n",
    "]\n",
    "p = sp.Popen(command, stderr=sp.PIPE)\n",
    "if p.returncode != 0:\n",
    "    print(p.communicate()[1].decode())\n",
    "with open('test.xlnet', 'rt') as file:\n",
    "    for line in file.readlines():\n",
    "        display(HTML('<p>' + line + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mw1_5HFpPHXA"
   },
   "source": [
    "# GPT-2\n",
    "[Better Language Models and Their Implications](https://openai.com/blog/better-language-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-gN6fB1Rr7h"
   },
   "source": [
    "### Instalar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:16:01.453291Z",
     "start_time": "2019-08-15T11:15:59.658501Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "jqpWEas7zw7P",
    "outputId": "90ebd8c5-6952-4cce-962f-3b6aa7f2394a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 81kB 5.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 604kB 14.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 23.1MB/s \n",
      "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!test -d gpt-2 || git clone --quiet https://github.com/nshepperd/gpt-2.git\n",
    "!pip install -q -r gpt-2/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Iij49z25SpD"
   },
   "source": [
    "### Importar los módulos de GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:29:41.293185Z",
     "start_time": "2019-08-17T08:29:40.868646Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "iMdg--TD5DDG",
    "outputId": "a7f4e265-6d6a-415d-9bdc-2975c26a1931"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 10:29:41.275823 140403767019328 deprecation_wrapper.py:119] From gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0817 10:29:41.290687 140403767019328 deprecation_wrapper.py:119] From gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not 'gpt-2' in sys.path:  # hack\n",
    "    sys.path += ['gpt-2']\n",
    "if not 'gpt-2/src' in sys.path:  # hack\n",
    "    sys.path += ['gpt-2/src']\n",
    "sys.argv = [\n",
    "    'train.py', '--dataset=../train.txt', '--model_name=345M',\n",
    "    '--memory_saving_gradients'\n",
    "]\n",
    "import train\n",
    "import model, sample, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkpW4YIFRnWf"
   },
   "source": [
    "### Descargar los pesos del modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:16:02.126806Z",
     "start_time": "2019-08-15T11:16:02.124548Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r8bVBQsB_oBk"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('gpt-2/models/345M'):\n",
    "    sp.call([sys.executable, 'download_model.py', '345M'], cwd='gpt-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2dTNhrkROWv"
   },
   "source": [
    "### Definir la función para generar textos\n",
    "\n",
    "Basado en https://github.com/openai/gpt-2/blob/master/src/interactive_conditional_samples.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:16:05.375154Z",
     "start_time": "2019-08-15T11:16:05.362027Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lJsfjW3fASYu"
   },
   "outputs": [],
   "source": [
    "def interact_model(prompt,\n",
    "                   model_name='117M',\n",
    "                   seed=None,\n",
    "                   nsamples=1,\n",
    "                   batch_size=1,\n",
    "                   length=None,\n",
    "                   temperature=1,\n",
    "                   top_k=0,\n",
    "                   top_p=0.0):\n",
    "    \"\"\"\n",
    "    Interactively run the model\n",
    "    :model_name=117M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to reproduce\n",
    "     results\n",
    "    :nsamples=1 : Number of samples to return total\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "    :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling,\n",
    "     overriding top_k if set to a value > 0. A good setting is 0.9.\n",
    "    \"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "    assert nsamples % batch_size == 0\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(cwd + '/gpt-2')  # hack\n",
    "    raw_text = prompt\n",
    "    texts = []\n",
    "\n",
    "    try:\n",
    "        enc = encoder.get_encoder(model_name)\n",
    "        hparams = model.default_hparams()\n",
    "        with open(os.path.join('models', model_name, 'hparams.json')) as f:\n",
    "            hparams.override_from_dict(json.load(f))\n",
    "\n",
    "        if length is None:\n",
    "            length = hparams.n_ctx // 2\n",
    "        elif length > hparams.n_ctx:\n",
    "            raise ValueError(\"Can't get samples longer than window size: %s\" %\n",
    "                             hparams.n_ctx)\n",
    "\n",
    "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "        output = sample.sample_sequence(hparams=hparams,\n",
    "                                        length=length,\n",
    "                                        context=context,\n",
    "                                        batch_size=batch_size,\n",
    "                                        temperature=temperature,\n",
    "                                        top_k=top_k,\n",
    "                                        top_p=top_p)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join('models', model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        context_tokens = enc.encode(raw_text)\n",
    "        for _ in range(nsamples // batch_size):\n",
    "            out = sess.run(output,\n",
    "                           feed_dict={\n",
    "                               context:\n",
    "                               [context_tokens for _ in range(batch_size)]\n",
    "                           })[:, len(context_tokens):]\n",
    "            for i in range(batch_size):\n",
    "                texts += [enc.decode(out[i])]\n",
    "\n",
    "    except:\n",
    "        os.chdir(cwd)  # hack\n",
    "        raise\n",
    "    os.chdir(cwd)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yskrmEFWNIl"
   },
   "source": [
    "### Especificar los checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:33:10.782600Z",
     "start_time": "2019-08-17T08:33:10.777589Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4D3vkm1iWK4k",
    "outputId": "a27a6cf5-04a9-4343-adf5-8764e0385ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"model.ckpt\"\n"
     ]
    }
   ],
   "source": [
    "# modelo pre-entrenado\n",
    "checkpoint_num = ''\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"model.ckpt\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDVL323ARG34"
   },
   "source": [
    "### Generar muestras con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:17:31.157250Z",
     "start_time": "2019-08-15T11:17:00.085037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gq6s-tH1ljXu",
    "outputId": "8ff49c27-4314-413f-ed7e-c43b5f77bd6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 1 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that?</b></i><br><br>MARY: Leon is the mildest of all creatures.<br><br>LEON: But’I've done the necessary work, Mary.’All of the restraint, all of the restraint. And I want you to know that you did it for me, did you, the only animals who could be my friends in a world not a fair one.<br><br>MARY: Think you're so good at your job’don't you just’just I want to look for little things that are different with a human.<br><br>LEON: But you look to the tern if you want to be grateful, you're needed. And here’well,’or’that's where a little help was needed, there to give me a hug. You've stopped me many times before, saying, \"I’can't make it, I‖ve grown tired‖ but if you just care‖ and just hope that I‖ll‖ give you a safe, carefree trip‖ a good trip.<br><br>MARY: I do hope that it is really a safe, carefree trip,’but I understand that you‖ll certainly have difficulty with one lucky trip. It makes you a lot harder to understand when people ask‖ \"How you helped Mary‖s trip?\"‖ Mary never asked you to help her trip!‖<br><br>LEON: Wait, what‖? Is‖ing helping a human‖ your friend,‖ is it‖ or‖ are you‖ or‖ are you‖ making it worse‖?‖<br><br><br>What happens if you ask me questions‖ do I think it's‖ okay‖ to know your answer‖ (pause) What about‖ are‖ are‖ are‖ are‖ it‖ okay‖ to be sad and sad and sad ‖?‖ (pause)<br><br>(Yes, female input) Mary‖!‖<br><br>The tortoise sobbing and pleading.<br><br>Master Shepherd Restraining! This tortoise has its head on your shoulder, can't hear.<br><br>How do you think about ways of helping others that you believe relieve stress in your life, things in your life that you need help‖?<br><br>Let me be your partner,<br><br>I have confidence in you, so do I!<br><br>You still need some</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 2 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that?</b></i> Why can't the turtle turn around? So then you crawl up on its back and kill it, right? But it's only alive if you kill this tortoise. Not only that, but the girl you were chasing on your quest to kill Leon is also the one chasing you, so it's important to kill her. It seems all this does is draw attention away from you. But then, someone steps forward and calls out \"That animal is trying to escape. It's hunting us!\" No! That's not right. This tortoise will only have you dead if you kill it. I thought it would eat Leon. It should say something, but it seems as if this tortoise has something else in mind. What the heck does it want? Cut it, it says! Are you crying? - I don't want to hear you cry, is what I thought. And so you stab the tortoise in the heart with a dirk, and bring it back to your lair. You place it on your tombstone, and tell anyone who'll listen about your destiny to move on to the next step. The steps of burying your dead could be numbered, I suppose. - Well, that was a bit late for me, so if anyone wants to come find me in 1.5 years, they could come ask me who I really am and where my true home lies. *A graveyard opened up in the distance. A voice caught my attention.* We should come by, girl. *Wait here. She moves in, and you enter. The grave, as you can see, had been properly dug. You had prepared the body so that it would not fade into nothingness when the tomb was opened. The body was still warm and soft, though in all likelihood the fire had woken it up. You wore a pair of small blue boots, one day you would wear them again. You are carrying an ebony bracelet around your neck. Then you raise the scabbard and lay it on the ground, there, there! You take a deep breath. Keep it close, she says. And there it is: The body of your lover. She is definitely weak, but she's right next to you. If I am she needs you and you need me. You and I are getting back together. You pull out the bracelet, and see the hole in the top. There is no silence after this. --- \"Uncle Strider.\" Strider: It is not with the body I bear your ashes, I suppose</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 3 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can’t, not without your help. But you’re not helping. Why is that?</b></i> you ask. It comes to you; it's not your fault. Is’it’wrong’you―’grin.‖ ‗An American‖ ‗Jules‖ ‗produces this film about an endurance event for Gold Medal-winning Americans at the Olympic Games.\" I do not know, if I was there and I was wearing that medal, and if I lived in Los Angeles at that time, it wouldn't have been such a big deal. In fact, if I lived in Las Vegas, it wouldn't have been that big a deal. An endurance event was a sort of cool sport‖‖ it was warm, casual, you might not need gloves. You didn‖t need umbrellas or anything, so, by going out, you did the workout. I had another contest at a toy store, a guy named David looked at me, laughed at me and told me to check that out. He was just kind of joking around when I told him about going to the gym. He didn't say anything about me. We got the three of us there on a business trip, we didn't even have to talk to anybody. He was like, \"you'd look great with the big, chestnut physique that you have. You'd be very athletic for you.\"<br><br>I remember being so shocked. People didn't want me to move it! I wanted to stay, and I still think about it now, I've fallen in love with a terrific physical community: Kataa Airel, Anfernghet, China Beach as far back as I remember, the Millennium Olympic Park and California mountains. How did they develop endurance athletes? The answer is because you wanted to run fast. Run from China, run with Dancer from Tibet, move fast, you wanted to be fast. But the question is, where do you start? The physicality comes along with discipline in order to deal with things like social or sexual harassment. You may be running in a random venue, then you may meet someone who is very attractive and makes this pithy comment, 'all you've got to do is show it.' Do you just crush your knees, move your legs and then bang into your buddy until your pussy gets teary-eyed? My point is: if you're starting now, do the trials. To me, performance workouts didn't end bad. On paper, we look on and marvel at what we've accomplished. We're</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo = \"You're in a desert, walking along in the sand, when all of a sudden you look down and see a tortoise, Leon. It's crawling toward you. You reach down, you flip the tortoise over on its back. The tortoise lays on its back, its belly baking in the hot sun, beating its legs trying to turn itself over, but it can\\u2019t, not without your help. But you\\u2019re not helping. Why is that?\"  #@param {type : 'string'}\n",
    "numero_de_muestras = 3  #@param {type : 'number'}\n",
    "temperature = 1  #@param {type : 'number'}\n",
    "#@markdown La temperatura controla el grado de aleatoriedad (0 = determinista)\n",
    "top_k = 40  #@param {type : 'integer'}\n",
    "#@markdown Número de candidatos considerados en el beam search (0 = \"greedy\", funciona bien con 40)\n",
    "top_p = 0.9  #@param {type : 'number'}\n",
    "#@markdown Controla la diversidad. (0 = valor por defecto, funciona bien con 0.9)\n",
    "texts = interact_model(prompt=ejemplo,\n",
    "                       model_name='345M',\n",
    "                       nsamples=numero_de_muestras,\n",
    "                       temperature=temperature,\n",
    "                       top_k=top_k,\n",
    "                       top_p=top_p)\n",
    "for i, text in enumerate(texts):\n",
    "    display(\n",
    "        HTML('<p>' + \"=\" * 40 + \" SAMPLE \" + str(i + 1) + \" \" + \"=\" * 40 +\n",
    "             '</p>'))\n",
    "    display(\n",
    "        HTML('<p>' +\n",
    "             ('<b><i>' + ejemplo + '</b></i>' + text).replace('\\n', '<br>') +\n",
    "             '</p>'))\n",
    "    display(HTML('<p>' + \"=\" * 80 + '</p>'))\n",
    "    display(HTML('<p><br></p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3PU6QOz0Pva"
   },
   "source": [
    "https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45QUnzzAnDbT"
   },
   "source": [
    "### Contestar una pregunta sobre un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "colab_type": "code",
    "id": "-DsXfTZBra-M",
    "outputId": "625d7ae1-9cca-45bd-c138-16a12d992d99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer <br>Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in <br>Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried <br>the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started <br>ahead of the 1936 Summer Olympics. <br><br>After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the <br>Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was <br>following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing <br>ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of <br>Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the <br>event. <br><br>Q: What was the theme <br>A: “one world, one dream”. <br>Q: What was the length of the race? <br>A: 137,000 km <br>Q: Was it larger than previous ones? <br>A: No <br>Q: Where did the race begin? <br>A: Olympia, Greece <br>Q: Is there anything notable about that place? <br>A: birthplace of Olympic Games <br>Q: Where did they go after? <br>A: Athens <br>Q: How many days was the race? <br>A: seven <br>Q: Did they visit any notable landmarks? <br>A: Panathinaiko Stadium <br><b><i>Q: And did they climb any mountains? <br>A:</b></i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> Mount Everest \n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexto = 'The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer \\n\\\n",
    "Olympics, with the theme of “one world, one dream”. Plans for the relay were announced on April 26, 2007, in \\n\\\n",
    "Beijing, China. The relay, also called by the organizers as the “Journey of Harmony”, lasted 129 days and carried \\n\\\n",
    "the torch 137,000 km (85,000 mi) – the longest distance of any Olympic torch relay since the tradition was started \\n\\\n",
    "ahead of the 1936 Summer Olympics. \\n\\\n",
    "\\n\\\n",
    "After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the \\n\\\n",
    "Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was \\n\\\n",
    "following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing \\n\\\n",
    "ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of \\n\\\n",
    "Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the \\n\\\n",
    "event. \\n\\\n",
    "\\n\\\n",
    "Q: What was the theme \\n\\\n",
    "A: “one world, one dream”. \\n\\\n",
    "Q: What was the length of the race? \\n\\\n",
    "A: 137,000 km \\n\\\n",
    "Q: Was it larger than previous ones? \\n\\\n",
    "A: No \\n\\\n",
    "Q: Where did the race begin? \\n\\\n",
    "A: Olympia, Greece \\n\\\n",
    "Q: Is there anything notable about that place? \\n\\\n",
    "A: birthplace of Olympic Games \\n\\\n",
    "Q: Where did they go after? \\n\\\n",
    "A: Athens \\n\\\n",
    "Q: How many days was the race? \\n\\\n",
    "A: seven \\n\\\n",
    "Q: Did they visit any notable landmarks? \\n\\\n",
    "A: Panathinaiko Stadium \\n'\n",
    "\n",
    "pregunta = 'Q: And did they climb any mountains? \\n\\\n",
    "A:'\n",
    "\n",
    "display(\n",
    "    HTML('<p>' +\n",
    "         (contexto + '<b><i>' + pregunta + '</b></i>').replace('\\n', '<br>') +\n",
    "         '</p>'))\n",
    "texts = interact_model(prompt=contexto + pregunta,\n",
    "                       model_name='345M',\n",
    "                       temperature=0.001)\n",
    "answer = texts[0][:texts[0].find('Q')]\n",
    "display(HTML('<p>' + answer + '</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "alhg-bLiKQbD",
    "outputId": "127f2876-7c26-4cd3-8855-bcf1a8e67d54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Tom goes everywhere with Catherine Green, a 54-year-old secretary. He moves around her office at work and goes <br>shopping with her. ”Most people don’t seem to mind Tom,” says Catherine, who thinks he is wonderful. ”He’s my <br>fourth child,” she says. She may think of him and treat him that way as her son. He moves around buying his food, <br>paying his health bills and his taxes, but in fact Tom is a dog. <br><br>Catherine and Tom live in Sweden, a country where everyone is expected to lead an orderly life according to rules <br>laid down by the government, which also provides a high level of care for its people. This level of care <br>costs money. <br><br>People in Sweden pay taxes on everything, so aren’t surprised to find that owning a dog means more <br>taxes. Some people are paying as much as 500 Swedish kronor in taxes a year for the right to keep their dog, which <br>is spent by the government on dog hospitals and sometimes medical treatment for a dog that falls ill. However, most <br>such treatment is expensive, so owners often decide to offer health and even life for their dog. <br><br>In Sweden dog owners must pay for any damage their dog does. A Swedish Kennel Club official explains what this means: <br>if your dog runs out on the road and gets hit by a passing car, you, as the owner, have to pay <br>for any damage done to the car, even if your dog has been killed in the accident. <br><br>Q: How old is Catherine? <br>A: 54 <br><b><i>Q: where does she live? <br>A:</b></i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> in Sweden. She lives in a small apartment in a small town in the north of Sweden. She is a single mother of two children. She is a member of the Swedish Kennel Club.\n",
       "\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexto = 'Tom goes everywhere with Catherine Green, a 54-year-old secretary. He moves around her office at work and goes \\n\\\n",
    "shopping with her. ”Most people don’t seem to mind Tom,” says Catherine, who thinks he is wonderful. ”He’s my \\n\\\n",
    "fourth child,” she says. She may think of him and treat him that way as her son. He moves around buying his food, \\n\\\n",
    "paying his health bills and his taxes, but in fact Tom is a dog. \\n\\\n",
    "\\n\\\n",
    "Catherine and Tom live in Sweden, a country where everyone is expected to lead an orderly life according to rules \\n\\\n",
    "laid down by the government, which also provides a high level of care for its people. This level of care \\n\\\n",
    "costs money. \\n\\\n",
    "\\n\\\n",
    "People in Sweden pay taxes on everything, so aren’t surprised to find that owning a dog means more \\n\\\n",
    "taxes. Some people are paying as much as 500 Swedish kronor in taxes a year for the right to keep their dog, which \\n\\\n",
    "is spent by the government on dog hospitals and sometimes medical treatment for a dog that falls ill. However, most \\n\\\n",
    "such treatment is expensive, so owners often decide to offer health and even life for their dog. \\n\\\n",
    "\\n\\\n",
    "In Sweden dog owners must pay for any damage their dog does. A Swedish Kennel Club official explains what this means: \\n\\\n",
    "if your dog runs out on the road and gets hit by a passing car, you, as the owner, have to pay \\n\\\n",
    "for any damage done to the car, even if your dog has been killed in the accident. \\n\\\n",
    "\\n\\\n",
    "Q: How old is Catherine? \\n\\\n",
    "A: 54 \\n'\n",
    "\n",
    "pregunta = 'Q: where does she live? \\n\\\n",
    "A:'\n",
    "\n",
    "display(\n",
    "    HTML('<p>' +\n",
    "         (contexto + '<b><i>' + pregunta + '</b></i>').replace('\\n', '<br>') +\n",
    "         '</p>'))\n",
    "texts = interact_model(prompt=contexto + pregunta,\n",
    "                       model_name='345M',\n",
    "                       temperature=0.001)\n",
    "answer = texts[0][:texts[0].find('Q')]\n",
    "display(HTML('<p>' + answer + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76OckKscm3W5"
   },
   "source": [
    "### Resumir un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gPtPeYo9iGWn",
    "outputId": "45b7f823-cc2b-41a9-8237-aae8fc974f11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>1. Introduction <br><br>Machine learning systems now excel (in expectation) at <br>tasks they are trained for by using a combination of large <br>datasets, high-capacity models, and supervised learning <br>(Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei <br>et al., 2016). Yet these systems are brittle and sensitive to <br>slight changes in the data distribution (Recht et al., 2018) <br>and task specification (Kirkpatrick et al., 2017). Current <br>systems are better characterized as narrow experts rather than <br>competent generalists. We would like to move towards more <br>general systems which can perform many tasks – eventually <br>without the need to manually create and label a training <br>dataset for each one. <br><br>The dominant approach to creating ML systems is to collect a <br>dataset of training examples demonstrating correct <br>behavior for a desired task, train a system to imitate these <br>behaviors, and then test its performance on independent <br>and identically distributed (IID) held-out examples. This <br>has served well to make progress on narrow experts. But <br>the often erratic behavior of captioning models (Lake et al., <br>2017), reading comprehension systems (Jia & Liang, 2017), <br>and image classifiers (Alcorn et al., 2018) on the diversity <br>and variety of possible inputs highlights some of the shortcomings <br>of this approach. <br><br>Our suspicion is that the prevalence of single task training <br>on single domain datasets is a major contributor to the lack <br>of generalization observed in current systems. Progress <br>towards robust systems with current architectures is likely <br>to require training and measuring performance on a wide <br>range of domains and tasks. Recently, several benchmarks <br>have been proposed such as GLUE (Wang et al., 2018) and <br>decaNLP (McCann et al., 2018) to begin studying this. <br><br>Multitask learning (Caruana, 1997) is a promising framework for <br>improving general performance. However, multitask training in NLP <br>is still nascent. Recent work reports modest performance <br>improvements (Yogatama et al., <br>2019) and the two most ambitious efforts to date have <br>trained on a total of 10 and 17 (dataset, objective) <br>pairs respectively (McCann et al., 2018) (Bowman et al., <br>2018). From a meta-learning perspective, each (dataset, <br>objective) pair is a single training example sampled <br>from the distribution of datasets and objectives. Current <br>ML systems need hundreds to thousands of examples to <br>induce functions which generalize well. This suggests that <br>multitask training many need just as many effective training <br>pairs to realize its promise with current approaches. It will <br>be very difficult to continue to scale the creation of datasets <br>and the design of objectives to the degree that may be required  <br>to brute force our way there with current techniques. <br>This motivates exploring additional setups for performing <br>multitask learning. <br><b><i>TL;DR:</b></i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> We propose a novel approach to training ML systems which \n",
       "allows for the creation of large datasets and large \n",
       "objectives.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexto = '1. Introduction \\n\\\n",
    "\\n\\\n",
    "Machine learning systems now excel (in expectation) at \\n\\\n",
    "tasks they are trained for by using a combination of large \\n\\\n",
    "datasets, high-capacity models, and supervised learning \\n\\\n",
    "(Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei \\n\\\n",
    "et al., 2016). Yet these systems are brittle and sensitive to \\n\\\n",
    "slight changes in the data distribution (Recht et al., 2018) \\n\\\n",
    "and task specification (Kirkpatrick et al., 2017). Current \\n\\\n",
    "systems are better characterized as narrow experts rather than \\n\\\n",
    "competent generalists. We would like to move towards more \\n\\\n",
    "general systems which can perform many tasks – eventually \\n\\\n",
    "without the need to manually create and label a training \\n\\\n",
    "dataset for each one. \\n\\\n",
    "\\n\\\n",
    "The dominant approach to creating ML systems is to collect a \\n\\\n",
    "dataset of training examples demonstrating correct \\n\\\n",
    "behavior for a desired task, train a system to imitate these \\n\\\n",
    "behaviors, and then test its performance on independent \\n\\\n",
    "and identically distributed (IID) held-out examples. This \\n\\\n",
    "has served well to make progress on narrow experts. But \\n\\\n",
    "the often erratic behavior of captioning models (Lake et al., \\n\\\n",
    "2017), reading comprehension systems (Jia & Liang, 2017), \\n\\\n",
    "and image classifiers (Alcorn et al., 2018) on the diversity \\n\\\n",
    "and variety of possible inputs highlights some of the shortcomings \\n\\\n",
    "of this approach. \\n\\\n",
    "\\n\\\n",
    "Our suspicion is that the prevalence of single task training \\n\\\n",
    "on single domain datasets is a major contributor to the lack \\n\\\n",
    "of generalization observed in current systems. Progress \\n\\\n",
    "towards robust systems with current architectures is likely \\n\\\n",
    "to require training and measuring performance on a wide \\n\\\n",
    "range of domains and tasks. Recently, several benchmarks \\n\\\n",
    "have been proposed such as GLUE (Wang et al., 2018) and \\n\\\n",
    "decaNLP (McCann et al., 2018) to begin studying this. \\n\\\n",
    "\\n\\\n",
    "Multitask learning (Caruana, 1997) is a promising framework for \\n\\\n",
    "improving general performance. However, multitask training in NLP \\n\\\n",
    "is still nascent. Recent work reports modest performance \\n\\\n",
    "improvements (Yogatama et al., \\n\\\n",
    "2019) and the two most ambitious efforts to date have \\n\\\n",
    "trained on a total of 10 and 17 (dataset, objective) \\n\\\n",
    "pairs respectively (McCann et al., 2018) (Bowman et al., \\n\\\n",
    "2018). From a meta-learning perspective, each (dataset, \\n\\\n",
    "objective) pair is a single training example sampled \\n\\\n",
    "from the distribution of datasets and objectives. Current \\n\\\n",
    "ML systems need hundreds to thousands of examples to \\n\\\n",
    "induce functions which generalize well. This suggests that \\n\\\n",
    "multitask training many need just as many effective training \\n\\\n",
    "pairs to realize its promise with current approaches. It will \\n\\\n",
    "be very difficult to continue to scale the creation of datasets \\n\\\n",
    "and the design of objectives to the degree that may be required  \\n\\\n",
    "to brute force our way there with current techniques. \\n\\\n",
    "This motivates exploring additional setups for performing \\n\\\n",
    "multitask learning. \\n'\n",
    "\n",
    "pregunta = 'TL;DR:'  # Too Long; Didn't Read (¡resúmelo por favor!)\n",
    "\n",
    "display(\n",
    "    HTML('<p>' +\n",
    "         (contexto + '<b><i>' + pregunta + '</b></i>').replace('\\n', '<br>') +\n",
    "         '</p>'))\n",
    "texts = interact_model(prompt=contexto + pregunta,\n",
    "                       model_name='345M',\n",
    "                       temperature=0.001)\n",
    "answer = texts[0][:texts[0].find('.') + 1]\n",
    "display(HTML('<p>' + answer + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AI9Ys9-gQKbh"
   },
   "source": [
    "### Descargar un texto para fine-tunear el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:27:27.838596Z",
     "start_time": "2019-08-17T08:27:26.585770Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vGi73ipH0lMn",
    "outputId": "15877ffd-3a78-4b53-c880-03b986469f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://docs.google.com/uc?export=download&id=1yQgoz5QmvbxQzN2TZWWjvniPqDhGoC8W\n",
      "278528/271286 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./train.txt'):\n",
    "    os.remove('./train.txt')\n",
    "\n",
    "# The Hitchhikers Guide to the Galaxy\n",
    "get_file(\n",
    "    os.getcwd() + '/train.txt',\n",
    "    origin=\n",
    "    'https://docs.google.com/uc?export=download&id=1yQgoz5QmvbxQzN2TZWWjvniPqDhGoC8W'\n",
    ")\n",
    "\n",
    "# Lord of the Rings : The Fellowship of the Ring\n",
    "# get_file(\n",
    "#     os.getcwd() + '/train.txt',\n",
    "#     origin=\n",
    "#     'https://docs.google.com/uc?export=download&id=1kZOHpaPV2ml8rT9l_bbWPt06H6qz-kcm'\n",
    "# )\n",
    "\n",
    "# Game of Thrones: A Song of Fire and Ice\n",
    "# get_file(\n",
    "#     os.getcwd() + '/train.txt',\n",
    "#     origin=\n",
    "#     'https://docs.google.com/uc?export=download&id=1saZmZA07QAqkG-afxlHDPEXNhDNV8Qka'\n",
    "# )\n",
    "\n",
    "# Cien Años de Soledad (no funciona muy bien al no haber sido entrenado en español el modelo...)\n",
    "# get_file(\n",
    "#     os.getcwd() + '/train.txt',\n",
    "#     origin=\n",
    "#     'https://docs.google.com/uc?export=download&id=1XDJmGP9MtOLQSujO5Voicp1wyekHchpm'\n",
    "# )\n",
    "\n",
    "# Harry Potter and the Goblet of Fire\n",
    "# get_file(\n",
    "#     os.getcwd() + '/train.txt',\n",
    "#     origin=\n",
    "#     'https://docs.google.com/uc?export=download&id=10OhbIQHNJrtBiKer8tP_LbxjASqItNzZ'\n",
    "# )\n",
    "\n",
    "# Trump's pearls of wisdom (http://www.trumptwitterarchive.com/archive)\n",
    "# get_file(\n",
    "#     os.getcwd() + '/train.txt',\n",
    "#     origin=\n",
    "#     'https://docs.google.com/uc?export=download&id=1d7g95QNkpvC4bwy5xtsC33JYb-AxvJ-q'\n",
    "# )\n",
    "\n",
    "encoding = 'cp1252' if os.name == 'nt' else 'utf-8'\n",
    "raw_text = ''\n",
    "with open('train.txt', 'r', encoding=encoding, errors='backslashreplace') as f:\n",
    "    raw_text += f.read()\n",
    "with open('train.txt', 'w', encoding=encoding, errors='backslashreplace') as f:\n",
    "    f.write(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joro1L73Qc8i"
   },
   "source": [
    "### Crear directorio para guardar los checkpoints (si estamos en Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T16:30:27.118211Z",
     "start_time": "2019-08-14T16:30:27.114590Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "TyyVsOx0lHhx",
    "outputId": "e0690699-5afe-4ef1-8cd3-8b0a547bc376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "try:  # estamos en Google Colab?\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    checkpoint_dir = '/content/drive/My Drive/Colab Notebooks/checkpoints'\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yskrmEFWNIl"
   },
   "source": [
    "### Especificar los checkpoints iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:33:10.782600Z",
     "start_time": "2019-08-17T08:33:10.777589Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4D3vkm1iWK4k",
    "outputId": "a27a6cf5-04a9-4343-adf5-8764e0385ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"model.ckpt\"\n"
     ]
    }
   ],
   "source": [
    "# modelo pre-entrenado\n",
    "checkpoint_num = ''\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"model.ckpt\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAC8hmQbQiqt"
   },
   "source": [
    "### Entrenar el modelo\n",
    "\n",
    "https://github.com/nshepperd/gpt-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:34:31.787256Z",
     "start_time": "2019-08-17T08:33:47.220824Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VPFHeGYW6sDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/345M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 64325 tokens\n",
      "Training...\n",
      "interrupted\n",
      "Saving /home/teticio/ML/aventuras-con-textos/checkpoints/run1/model-1\n"
     ]
    }
   ],
   "source": [
    "train.CHECKPOINT_DIR = checkpoint_dir\n",
    "tf.reset_default_graph()\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd + '/gpt-2')  # hack\n",
    "try:\n",
    "    train.main()\n",
    "except:\n",
    "    os.chdir(cwd)  # hack\n",
    "    raise\n",
    "os.chdir(cwd)  # hack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWqHS0LAQ3ET"
   },
   "source": [
    "### Especificar los checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "bkZcMgDsy2V3",
    "outputId": "5ddc77a3-d7c4-485d-c576-1fd2b19af8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"/content/drive/My Drive/Colab Notebooks/checkpoints/run1_Harry_Potter/model-16000\"\n"
     ]
    }
   ],
   "source": [
    "# modelo tuneado con Harry Potter and the Goblet of Fire\n",
    "checkpoint = checkpoint_dir + '/run1_Harry_Potter'\n",
    "checkpoint_num = '16000'\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"' + checkpoint + '/model-' + checkpoint_num + '\"'\n",
    "\n",
    "# modelo tuneado con Game of Thrones: A Song of Fire and Ice\n",
    "#checkpoint = checkpoint_dir + '/run1_GOT'\n",
    "#checkpoint_num = '18754'\n",
    "#model_checkpoint_path = 'model_checkpoint_path: \"' + checkpoint + '/model-' + checkpoint_num + '\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sL0Ve7HdRA1f"
   },
   "source": [
    "### Generar muestras con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zONNL240PcYv",
    "outputId": "1c73df8e-5276-42d6-b311-b84e0f60b7d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 1 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>CHAPTER 1 - The Return of Voldermort</b></i><br><br>The thunderous clunks of Hagrid’s heavy wooden dining-room door as it swung closed were a constant source of amusement to Harry. It was due to this, that he’s been using the excuse of a valuable lesson to get to bed early, and sneakogle away from Ron and Hermione for the last time.<br><br>Alarmed as he was at the idea of having to share a room with Ron and Hermione, Harry still didn’t think they were cruel people; on the contrary, both of them seemed quite capable of putting up with a lotlier than they did. Harry had knocked over his cauldron and spilled a considerable amount of its contents upon the floor, but he had yet to move an inch, while Hermione was being choked, bound, gagged and raped with her hands, repeatedly.<br><br>It was an appalling sight, seeing Hermione gagged, bound and raped with a Goblin Lord, seated behind her. The whole house was watching her, as though she were a demon possessed.<br><br>One by one, the ranks of spectators swelled. Witches and wizards from all over the country were coming to watch the most amazing scene of sorcery and murder Harry had ever witnessed.<br><br>Then a wizard just like Hermione appeared just behind Hermione. She was very short and round-faced, with a large orange nose and almond-shaped brown eyes. She was talking to Ludo Bagman, the Head of the International League of Zemouregal Wizards, in a soothing and even voice.<br><br>‘Ludo, could I have a sec … could I have a sec … could I?’<br><br>She saw, with a pinch of panic, that Bagman was leading a short, stout man into the room.<br><br>‘Ah, it’s Ludo!’ says Mr Bagman, grinning. ‘Ah, I see … aye, I see … a fine pair of chaps … you?’<br><br>‘I am,’ said Ludo, ‘yeh are.’<br><br>‘How long have you been here?’ says Bagman.<br><br>‘One year,’ says Ludo.<br><br>‘Ah, yes, I was just starting – soye hurry up!’<br><br>Bagman hurried along the table, and Harry saw Ludo Bagman putting his initials to the voter’s names.<br><br>‘Very interesting</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 2 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>CHAPTER 1 - The Return of Voldermort</b></i><br><br>When Harry awoke next morning, he knew he would not like to admit it; he was very angry with Voldermort for what Harry had said about Wormtail, and rightly so. The episode had shaken Harry so much that he had been unable to go to the library before the end of the term. He had been feeling very blue all through school, and by the time he got back to the castle after lunch, he was already wishing he could just keep going, throw the book under the kettle, and watch The Lord of the Rings …<br><br>But that wasn’t why he was writing. He was writing because he had been so wrong about Wormtail. It was time to walk the walk, and Harry was going to show Voldemort exactly how wrong he was.<br><br><br><br><br><br>— CHAPTER ONE —<br><br><br>The Russian Blood<br><br>Harry had walked around the edges of the dungeon for nearly four hours. He saw no sign of Voldemort’s ghost. Tired and lonely, he lay, apart from Ron and Hermione, listening to the wind outside outside. Hot, dry clothes felt slightly thin and stubbly under his fingers, and the breeze that blew across his face was somehow so gratifying to his ear that he had to suppress a pained sort of grumble.<br><br>He looked up at Harry.<br><br>‘You OK, Harry?’ he said.<br><br>‘Yeah,’ said Harry.<br><br>‘You needed to go to the hospital wing, it’s down the hill.’<br><br>‘Got a fever,’ said Harry.<br><br>‘Got a dragon?’ said Hermione. ‘Well, I’ve got a dragon,’ she added, and she was pointing at the unicorn shank that was stirring in the pan. The shank was moving, a curious sort of humming, as it aged.<br><br>‘I’ve got to go and see Professor Moody,’ Harry said, getting to his feet. ‘He’s been – he’s in a bad way. He kept disappearing … it’s probably back to the Dursleys wanting to get him back.’<br><br>‘Must be nice,’ said Hermione, pulling her scarf back over her head. ‘To have someone who’s so powerful try and take you from him.’<br><br>‘Yeah, it’s</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>======================================== SAMPLE 3 ========================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b><i>CHAPTER 1 - The Return of Voldermort</b></i><br><br><br><br>TWENTY-THREE<br><br>The Department of Mysteries<br><br><br><br>TWENTY-FOUR<br><br>Beyond the Veil<br><br><br><br>TWENTY-FIVE<br><br>The Madness of Mr Crouch<br><br><br><br>TWENTY-SIX<br><br>Something Wicked This Way Comes<br><br><br><br>TWENTY-SEVEN<br><br>The Dream<br><br><br><br>TWENTY-EIGHT<br><br>The Second Task<br><br><br><br>TWENTY-NINE<br><br>Veritaserum<br><br><br><br>TWENTY-TEN<br><br>Veritaserum<br><br><br><br>TWENTY-THIRTEEN<br><br>Veritasections<br><br><br><br>TWENTY-FOURTEEN<br><br>Veritisation<br><br><br><br>TWENTY-FIVETEEN<br><br>Veritisation<br><br><br><br>TWENTY-SIXTEEN<br><br>Veritisation<br><br><br><br>TWENTY-SEVENTEEN<br><br>Veritisation<br><br><br><br>TWENTY-EIGHTTEEN<br><br>Veritisation<br><br><br><br>TWENTY-NINETEEN<br><br>Veritisation<br><br><br><br>TWENTY-TENTEEN<br><br>Veritisation<br><br><br><br>TWENTY-TWELVE<br><br>Veritisation<br><br><br><br>TWENTY-THIRTEEN<br><br>Veritisation<br><br><br><br>TWENTY-FOURTEEN<br><br>Veritisation<br><br><br><br>TWENTY-FIVETEEN<br><br>Veritisation<br><br><br><br>TWENTY-SIXTEEN<br><br>Veritisation<br><br><br><br>TWENTY-SEVENTEEN<br><br>Veritisation<br><br><br><br>TWENTY-EIGHTTEEN<br><br>Veritisation<br><br><br><br>TWENTY-NINE<br><br>Veritisation<br><br><br><br>TWENTY-TEN<br><br>Veritisation<br><br><br><br>TWENTY-TWELVE<br><br>Veritisation<br><br><br><br>TWENTY-THIRTY<br><br>The Third Task<br><br><br><br>TWENTY-FOURTEEN<br><br>Veritisation<br><br><br><br>TWENTY-FIVE<br><br>The Fourth Task<br><br><br><br>TWENTY-SIXTEEN<br><br>Veritisation<br><br><br><br>TWENTY-SEVEN<br><br>The Seventh Task<br><br><br><br>TWENTY-EIGHT<br><br>Veritisation<br><br><br><br>TWENTY-NINE<br><br>Veritisation<br><br><br><br>TWENTY-</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>================================================================================</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo = 'CHAPTER 1 - The Return of Voldermort'  #@param {type : 'string'}\n",
    "numero_de_muestras = 3  #@param {type : 'number'}\n",
    "temperature = 1  #@param {type : 'number'}\n",
    "#@markdown La temperatura controla el grado de aleatoriedad (0 = determinista)\n",
    "top_k = 40  #@param {type : 'integer'}\n",
    "#@markdown Número de candidatos considerados en el beam search (0 = \"greedy\", funciona bien con 40)\n",
    "top_p = 0.9  #@param {type : 'number'}\n",
    "#@markdown Controla la diversidad. (0 = valor por defecto, funciona bien con 0.9)\n",
    "texts = interact_model(prompt=ejemplo,\n",
    "                       model_name='345M',\n",
    "                       nsamples=numero_de_muestras,\n",
    "                       temperature=temperature,\n",
    "                       top_k=top_k,\n",
    "                       top_p=top_p)\n",
    "for i, text in enumerate(texts):\n",
    "    display(\n",
    "        HTML('<p>' + \"=\" * 40 + \" SAMPLE \" + str(i + 1) + \" \" + \"=\" * 40 +\n",
    "             '</p>'))\n",
    "    display(\n",
    "        HTML('<p>' +\n",
    "             ('<b><i>' + ejemplo + '</b></i>' + text).replace('\\n', '<br>') +\n",
    "             '</p>'))\n",
    "    display(HTML('<p>' + \"=\" * 80 + '</p>'))\n",
    "    display(HTML('<p><br></p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxtpZl4Ltf01"
   },
   "source": [
    "### Traducir una frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urw1IW82tH95"
   },
   "outputs": [],
   "source": [
    "# puedes encontrar otros texto paralelos aquí\n",
    "# cuidado porque se actualizan periodicamente\n",
    "# https://www.manythings.org/anki/\n",
    "\n",
    "path_to_zip = get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin=\n",
    "    'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "path_to_file = os.path.dirname(path_to_zip) + \"/spa-eng/spa.txt\"\n",
    "\n",
    "frases = []\n",
    "with open(path_to_file, 'rt') as file:\n",
    "    for line in file.readlines():\n",
    "        tab = line.find('\\t')\n",
    "        frases += [line[:tab] + ' = ' + line[tab + 1:]]\n",
    "with open('train.txt', 'wt') as file:\n",
    "    for _ in np.random.choice(range(len(frases)), len(frases), replace=False):\n",
    "        file.write(frases[_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUYLJ3GreJ5-"
   },
   "source": [
    "### Especificar los checkpoints iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3-bsl8feeJ6H",
    "outputId": "a8428b7e-1b92-4c97-f53a-49fd1979b420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"model.ckpt\"\n"
     ]
    }
   ],
   "source": [
    "# modelo pre-entrenado\n",
    "checkpoint_num = ''\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"model.ckpt\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NbgqHJTea8k"
   },
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvfqdED_AHJ7"
   },
   "outputs": [],
   "source": [
    "train.CHECKPOINT_DIR = checkpoint_dir\n",
    "tf.reset_default_graph()\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd + '/gpt-2')  # hack\n",
    "try:\n",
    "    train.main()\n",
    "except:\n",
    "    os.chdir(cwd)  # hack\n",
    "    raise\n",
    "os.chdir(cwd)  # hack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pENG5_kYWYgt"
   },
   "source": [
    "### Especificar los checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:18:07.856161Z",
     "start_time": "2019-08-15T11:18:07.850638Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BMA8JAZqWYgw",
    "outputId": "c35c67fa-1c17-44a5-db66-6fc09c4a77cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"/home/teticio/ML/aventuras-con-textos/checkpoints/run1_spa-eng/model-45000\"\n"
     ]
    }
   ],
   "source": [
    "# modelo tuneado con traducciones de inglés a español\n",
    "checkpoint = checkpoint_dir + '/run1_spa-eng'\n",
    "checkpoint_num = '45000'\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"' + checkpoint + '/model-' + checkpoint_num + '\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:18:24.222280Z",
     "start_time": "2019-08-15T11:18:08.745727Z"
    },
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "-sSDW9HnAMxT",
    "outputId": "e9796956-30f6-44d0-888e-35be9dbbbde3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b><i>Who did you go to the movies with? =</b></i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> ¿Este es mienda con?\n",
       "I'm not going to hurt you.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo = \"Who did you go to the movies with? =\"  #@param {type : 'string'}\n",
    "numero_de_muestras = 1  #@param {type : 'number'}\n",
    "temperature = 0.1  #@param {type : 'number'}\n",
    "#@markdown La temperatura controla el grado de aleatoriedad (0 = determinista)\n",
    "top_k = 40  #@param {type : 'integer'}\n",
    "#@markdown Número de candidatos considerados en el beam search (0 = \"greedy\", funciona bien con 40)\n",
    "top_p = 0.1  #@param {type : 'number'}\n",
    "#@markdown Controla la diversidad. (0 = valor por defecto, funciona bien con 0.9)\n",
    "texts = interact_model(prompt=ejemplo,\n",
    "                       model_name='345M',\n",
    "                       nsamples=numero_de_muestras,\n",
    "                       temperature=temperature,\n",
    "                       top_k=top_k,\n",
    "                       top_p=top_p)\n",
    "display(HTML('<p><b><i>' + ejemplo + '</b></i></p>'))\n",
    "display(HTML('<p>' + texts[0][:texts[0].find('.') + 1] + '</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZialcwK1dtz_"
   },
   "source": [
    "### Trumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T12:10:18.606314Z",
     "start_time": "2019-08-15T12:10:18.539578Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Hl_yDtwPcZGs",
    "outputId": "da0ddeb6-7065-47f5-b9c8-1b7a0aaff5f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"/content/drive/My Drive/Colab Notebooks/checkpoints/run1_Trump/model-22000\"\n",
      "Downloading data from https://docs.google.com/uc?export=download&id=1d7g95QNkpvC4bwy5xtsC33JYb-AxvJ-q\n",
      "3121152/Unknown - 1s 0us/step"
     ]
    }
   ],
   "source": [
    "# modelo tuneado con los tweets de Trump\n",
    "checkpoint = checkpoint_dir + '/run1_Trump'\n",
    "checkpoint_num = '22000'\n",
    "model_checkpoint_path = 'model_checkpoint_path: \"' + checkpoint + '/model-' + checkpoint_num + '\"'\n",
    "\n",
    "with open('gpt-2/models/345M/checkpoint', \"wt\") as file:\n",
    "    print(model_checkpoint_path)\n",
    "    file.write(model_checkpoint_path)\n",
    "with open('gpt-2/models/345M/counter', \"wt\") as file:\n",
    "    file.write(f'{checkpoint_num}')\n",
    "\n",
    "get_file(\n",
    "    os.getcwd() + '/train.txt',\n",
    "    origin=\n",
    "    'https://docs.google.com/uc?export=download&id=1d7g95QNkpvC4bwy5xtsC33JYb-AxvJ-q'\n",
    ")\n",
    "encoding = 'cp1252' if os.name == 'nt' else 'utf-8'\n",
    "with open('train.txt', 'r', encoding=encoding, errors='backslashreplace') as f:\n",
    "    words = [\n",
    "        ' '.join(line.split()[0:2]) for line in f.readlines()\n",
    "        if len(line.split()) >= 2\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T11:57:03.888460Z",
     "start_time": "2019-08-15T11:51:42.148146Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "IwPHIAj9cZGw",
    "outputId": "a0110408-5518-42db-c0e5-31c2305850b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Mitt Romney  is the only one who can win. All others have failed.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Crazy Maureen  Smith who knows nothing about me started the Fake News because her show had zero credibility. She was very slanted against me. She is a sick &amp; perverted person!</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>.@MichaelPhelps--you are  a total winner &amp; a fantastic guy!</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>A big  day - victory in Georgia!</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>According to  @adamcasner the @WWE Hall of Fame should be in Pittsburgh not Washington. Don't worry though my pro-wrestling dreams will live on forever!</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Sorry losers  &amp; haters is at it again - blame it on \"the woman\" – new name: 'Cheri Cruz.' https://t.co/34DlgfeTF5</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Andy Roddick...a  terrible director. Not a good director.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>@RobertCherry1 Fantastic! </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Rubio was  born in Cuba and grew up there... https://t.co/3vHypMnQlZ</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>Hard to  believe the losers of the \"debate\" didn't realize that they were losing. Phony \"debate\" was a joke. \"@FoxNews  Fact-free zone- Ben Carson\" http://t.co/ASWubT6Zs6</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "numero_de_muestras = 10  #@param {type : 'number'}\n",
    "temperature = 1  #@param {type : 'number'}\n",
    "#@markdown La temperatura controla el grado de aleatoriedad (0 = determinista)\n",
    "top_k = 40  #@param {type : 'integer'}\n",
    "#@markdown Número de candidatos considerados en el beam search (0 = \"greedy\", funciona bien con 40)\n",
    "top_p = 0.9  #@param {type : 'number'}\n",
    "#@markdown Controla la diversidad. (0 = valor por defecto, funciona bien con 0.9)\n",
    "texts = []\n",
    "for _ in range(numero_de_muestras):\n",
    "    ejemplo = random.choice(words)\n",
    "    text = ejemplo + ' ' + interact_model(prompt=ejemplo,\n",
    "                                          model_name='345M',\n",
    "                                          nsamples=1,\n",
    "                                          temperature=temperature,\n",
    "                                          top_k=top_k,\n",
    "                                          top_p=top_p)[0]\n",
    "    display(\n",
    "        HTML(\n",
    "            '<p><img src=\"https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg\" width=48 align=left></img><b>Donald J. Trump</b> @realDonaldTrumpy<br>'\n",
    "            + text[:text.find('\\n')] + '</p>'))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Modelos generativos de texto de última generación",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
